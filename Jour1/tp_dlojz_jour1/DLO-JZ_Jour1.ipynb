{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLO-JZ Optimisation de l'apprentissage - Jour 1 \n",
    "\n",
    "Optimisation système d'une boucle d'apprentissage *Resnet-152*.\n",
    "\n",
    "![car](./images/optimisation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objet du notebook\n",
    "\n",
    "Le but de ce *notebook* est d'optimiser un code d'apprentissage d'un modèle *Resnet-50* sur *Imagenet* pour Jean Zay en implémentant :\n",
    "* **TP 1** : l'accélération GPU\n",
    "* **TP 2** : l'*Automatic Mixed Precision*\n",
    "* **TP 3** : le *Channels Last Memory Format*\n",
    "* **TP 4** : le *Profiler*\n",
    "\n",
    "Les cellules dans ce *notebook* ne sont pas prévues pour être modifiées, sauf rares exceptions indiquées dans les commentaires. Les TP se feront en modifiant les codes `dlojz1_X.py`.\n",
    "\n",
    "Les directives de modification seront marquées par l'étiquette **TODO** dans le *notebook* suivant.\n",
    " \n",
    "Les solutions sont présentes dans le répertoire `solutions/`.\n",
    "\n",
    "*Notebook rédigé par l'équipe assistance IA de l'IDRIS, juin 2023*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environnement de calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions *python* de gestion de queue SLURM dévelopées par l'IDRIS et les fonctions dédiées à la formation DLO-JZ sont à importer.\n",
    "\n",
    "Le module d'environnement pour les *jobs* et la taille des images sont fixés pour ce *notebook*.\n",
    "\n",
    "**TODO :** choisir un *pseudonyme* (maximum 5 caractères) pour vous différencier dans la queue SLURM et dans les outils collaboratifs pendant la formation et la compétition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from idr_pytools import display_slurm_queue, gpu_jobs_submitter, search_log\n",
    "from dlojz_tools import controle_technique, compare, GPU_underthehood, plot_accuracy, lrfind_plot, imagenet_starter\n",
    "MODULE = 'pytorch-gpu/py3/2.4.0'\n",
    "image_size = 224\n",
    "account = 'for@a100'\n",
    "name = 'pseudo'   ## Pseudonyme à choisir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un répertoire `checkpoints/` si cela n'a pas déjà été fait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion de la queue SLURM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour afficher vos jobs dans la queue SLURM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque**: Cette fonction est utilisée plusieurs fois dans ce *notebook*. Elle permet d'afficher la queue de manière dynamique, rafraichie toutes les 5 secondes. Elle ne s'arrête que lorsque la queue est vide. Si vous désirez reprendre la main sur le *notebook*, il vous suffira d'arrêter manuellement la cellule avec le bouton *stop*. Cela a bien sûr aucun impact les jobs soumis.\n",
    "\n",
    "Si vous voulez retirer TOUS vos jobs de la queue SLURM, décommenter et exécuter la cellule suivante :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!scancel -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous voulez retirer UN de vos jobs de la queue SLURM, décommenter, compléter et exécuter la cellule suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!scancel <jobid>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "### Différence entre deux scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour comparer son code avec les solutions mises à disposition, la fonction suivante permet d'afficher une page HTML contenant un différentiel de fichiers texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s1 = \"./dlojz1_1.py\"\n",
    "s2 = \"./solutions/dlojz1_1.py\"\n",
    "compare(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir le résultat du différentiel de fichiers sur la page suivante (attention au spoil !) :\n",
    "\n",
    "[compare.html](compare.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "## Dataset et modèle\n",
    "\n",
    "Cette partie permet de visualiser les caractéristiques du *dataset* et du modèle utilisés.\n",
    "\n",
    "### Imagenet\n",
    "\n",
    "#### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "        transforms.RandomResizedCrop(224),             # Random resize - Data Augmentation\n",
    "        transforms.RandomHorizontalFlip(),              # Horizontal Flip - Data Augmentation\n",
    "        transforms.ToTensor(),                          # convert the PIL Image to a tensor\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                             std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "    \n",
    "    \n",
    "train_dataset = torchvision.datasets.ImageNet(root=os.environ['ALL_CCFRSCRATCH']+'/imagenet',\n",
    "                                                  transform=transform)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,    \n",
    "                                           batch_size=4,\n",
    "                                           shuffle=True)\n",
    "batch = next(iter(train_loader))\n",
    "print('X train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[0].shape, batch[0].dtype, batch[0].element_size()*batch[0].nelement()))\n",
    "print('Y train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[1].shape, batch[1].dtype, batch[1].element_size()*batch[1].nelement()))\n",
    "\n",
    "img = batch[0][0].numpy().transpose((1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "labels_cls, labels_id = torch.load(os.environ['ALL_CCFRSCRATCH']+'/imagenet/meta.bin')\n",
    "label = labels_cls[np.unique(labels_id)[batch[1][0].numpy()]]\n",
    "_ = plt.title('label class: {}'.format(label[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose([\n",
    "                                    transforms.Resize((256, 256)),\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),   # convert the PIL Image to a tensor\n",
    "                                    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                    std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageNet(root=os.environ['ALL_CCFRSCRATCH']+'/imagenet', split='val',\n",
    "                        transform=val_transform)\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet-152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet152()\n",
    "print('number of total parameters: {}'.format(sum([p.numel() for p in model.parameters()])))\n",
    "print('number of trainable parameters: {}'.format(sum([p.numel() for p in model.parameters() if p.requires_grad])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1_0 : Baseline CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce TP consiste à appliquer le code *baseline* pour prendre en main les fonctionnalités de test et découvrir le code.\n",
    "\n",
    "**TODO :**\n",
    "1. Exécuter les cellules suivantes (le *job* prend plus de 10 minutes environ)\n",
    "2. Puis, ouvrir le fichier [dlojz1_0.py](dlojz1_0.py)\n",
    "\n",
    "Remarque :\n",
    "* l'option *test* lance un apprentissage de 50 itérations.\n",
    "* les chronomètres mesurent les temps de la 2e à la 50e itération et restitue un temps moyen par itération.\n",
    "* les parties `DON'T MODIFY` dans le script ne doivent pas être modifiées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_gpu = 1\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "command = f'./dlojz1_0.py -b {batch_size} --image-size {image_size} --test --no-pin-memory --test-nsteps 10'\n",
    "command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:20:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['159506']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizz\n",
    "\n",
    "L'éxécution étant assez longue (~ 10 min.), un quizz vous attend : [Quizz TP1_0](https://www.deepmama.com/quizz/dlojz_quizz1.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code *baseline* `dlojz1_0.py` a été exécuté sur le CPU (contrairement à ce qui est indiqué par le contrôle technique) en mode *test*, soit sur 50 itérations.\n",
    "\n",
    "Dans le prochain exercice nous verrons ensemble l'accélération sur 1 GPU.\n",
    "\n",
    "\n",
    "![Garage](images/stop.png \"Arrêtez-vous ici! Une présentation vous attend avant le prochain TP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1_1 : Accélération GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir la [documentation pytorch](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html)\n",
    "\n",
    "**TODO** : dans le script [dlojz1_1.py](./dlojz1_1.py):\n",
    "* Définir la variable `gpu` et envoyer le modèle dans la mémoire du GPU.\n",
    "\n",
    "* Envoyer toutes les *metrics* dans la mémoire du GPU.\n",
    "\n",
    "* Envoyer les *batches* d'images d'entrée et les *labels* associés sur le GPU, pour **les étapes de *training* et de *validation***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_gpu = 1\n",
    "batch_size = 128\n",
    "command = f'./dlojz1_1.py -b {batch_size} --image-size {image_size} --test'\n",
    "command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz1_1.py -b {batch_size} --image-size {image_size} --test'\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['159564']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizz\n",
    "\n",
    "L'éxécution étant assez longue, un quizz vous attend : [Quizz TP1_1](https://www.deepmama.com/quizz/dlojz_quizz2.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test d'occupation mémoire\n",
    "\n",
    "Afin de mesurer l'impact de la taille de batch sur l'occupation mémoire et sur le *throughput*, la cellule suivante permet de soumettre plusieurs *jobs* avec des tailles de *batch* croissantes. Dans les cas où la mémoire est saturée et dépasse la capacité du GPU, le système renverra une erreur *CUDA Out of Memory*.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_gpu = 1\n",
    "batch_size = [8, 16, 32, 64, 128, 256, 512]\n",
    "command = [f'./dlojz1_1.py -b {b} --image-size {image_size} --test'\n",
    "          for b in batch_size]\n",
    "jobids = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobids = {jobids}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobids = ['xxxxx', ...]` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobids = ['902357', '902358', '902359', '902360', '902361', '902362', '902363', '902365']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GPU_underthehood(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dernier *job* a atteint le seuil *CUDA Out Of Memory* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique([jobids[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Garage](images/stop.png \"Arrêtez-vous ici! Une présentation vous attend avant le prochain TP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1_2 : Automatic Mixed Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir la [documentation de l'IDRIS](http://www.idris.fr/ia/mixed-precision.html#en_pytorch)\n",
    "\n",
    "**TODO** : dans le script [dlojz1_2.py](./dlojz1_2.py):\n",
    "* Importer les fonctionnalités liées à l'*Automatic Mixed Precision*.\n",
    "\n",
    "* Initialiser le *scaler*.  \n",
    "\n",
    "* Implémenter l'*autocasting* (le changement de précision, FP32 à FP16) dans le *forward* , avec la ligne `with autocast():` dans la boucle de *training* **et** la boucle de validation.\n",
    "\n",
    "* Implémenter le *gradient scaling* pour la seule boucle de *training*. **Note**: À la place des lignes `loss.backward()` et `optimizer.step()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_gpu = 1\n",
    "batch_size = 128\n",
    "command = f'./dlojz1_2.py -b {batch_size} --image-size {image_size} --test'\n",
    "command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz1_2.py -b {batch_size} --image-size {image_size} --test'\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['902431']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizz\n",
    "\n",
    "L'éxécution étant assez longue, un quizz vous attend : [Quizz TP1_2](https://www.deepmama.com/quizz/dlojz_quizz3.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test d'occupation mémoire\n",
    "\n",
    "Afin de mesurer l'impact de la taille de batch sur l'occupation mémoire et sur le *throughput*, la cellule suivante permet de soumettre plusieurs *jobs* avec des tailles de *batch* croissantes. Dans les cas où la mémoire est saturée et dépasse la capacité du GPU, le système renverra une erreur *CUDA Out of Memory*.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "n_gpu = 1\n",
    "batch_size = [16, 32, 64, 128, 256, 512, 1024]\n",
    "command = [f'./dlojz1_2.py -b {b} --image-size {image_size} --test'\n",
    "          for b in batch_size]\n",
    "jobids = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobids = {jobids}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobids = ['xxxxx', ...]` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobids = ['903148', '903150', '903151', '903152', '903154', '903155', '903156', '903157']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GPU_underthehood(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changement de taille de batch\n",
    "\n",
    "**TODO :** Choisir pour la suite du TP une taille de batch par GPU qui vous semble la plus pertinente selon le test précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Choisir un batch size optimal\n",
    "bs_optim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_gpu = 1\n",
    "command = f'./dlojz1_2.py -b {bs_optim} --image-size {image_size} --test'\n",
    "command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz1_2.py -b {bs_optim} --image-size {image_size} --test'\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobids = ['xxxxx', ...]` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['903167']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Commentaires](images/cedez.png \"Assurez-vous que tout se passe bien avant de continuer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1_3 : Channels Last Memory Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir la [documentation pytorch](https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html)\n",
    "\n",
    "**TODO** : dans le script [dlojz1_3.py](./dlojz1_3.py):\n",
    "* Lors de l'envoie du modèle au GPU, configurer le paramètre `memory_format` avec l'option *Channel Last Memory*.\n",
    "\n",
    "* Lors de l'envoie des images d'entrée au GPU, configurer le paramètre `memory_format` avec l'option *Channel Last Memory*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_gpu = 1\n",
    "command = f'./dlojz1_3.py -b {bs_optim} --image-size {image_size} --test'\n",
    "command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz1_3.py -b {bs_optim} --image-size {image_size} --test'\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobids = ['xxxxx', ...]` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['902659']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test d'occupation mémoire\n",
    "\n",
    "Afin de mesurer l'impact de la taille de batch sur l'occupation mémoire et sur le *throughput*, la cellule suivante permet de soumettre plusieurs *jobs* avec des tailles de *batch* croissantes. Dans les cas où la mémoire est saturée et dépasse la capacité du GPU, le système renverra une erreur *CUDA Out of Memory*.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "n_gpu = 1\n",
    "batch_size = [16, 32, 64, 128, 256, 512, 1024]\n",
    "command = [f'./dlojz1_3.py -b {b} --image-size {image_size} --test'\n",
    "          for b in batch_size]\n",
    "jobids = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobids = {jobids}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobids = ['xxxxx', ...]` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobids = ['2069429', '2069430', '2069431', '2069432', '2069433', '2069435', '2069437']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GPU_underthehood(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Garage](images/stop.png \"Arrêtez-vous ici! Une présentation vous attend avant le prochain TP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## Garage - Mise à niveau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fixe le *batch size* et la taille d'image pour ce TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1_4 : Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation du profiler PyTorch\n",
    "\n",
    "Voir la [documentation de l'IDRIS](http://www.idris.fr/jean-zay/pre-post/profiler_pt.html).\n",
    "\n",
    "**TODO** : dans le script [dlojz1_4.py](./dlojz1_4.py) :\n",
    "\n",
    "* Importer les librairies liées au *profiler* PyTorch.\n",
    "\n",
    "* Configurer le *profiler* et ses paramètres.\n",
    "\n",
    "```python\n",
    "    # pytorch profiler setup\n",
    "\tprof =  profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                    schedule=schedule(wait=1, warmup=1, active=5, repeat=1),\n",
    "                    on_trace_ready=tensorboard_trace_handler('./profiler/' + os.environ['SLURM_JOB_NAME'] \n",
    "                                               + '_' + os.environ['SLURM_JOBID'] + '_bs' +\n",
    "                                               str(mini_batch_size)  + '_is' + str(args.image_size)),\n",
    "                    profile_memory=True,\n",
    "                    record_shapes=False, \n",
    "                    with_stack=False,\n",
    "                    with_flops=False\n",
    "                    )\n",
    "```\n",
    "\n",
    "* Englober toute la boucle d'apprentissage (validation comprise) dans le *context* `prof`.\n",
    "\n",
    "\n",
    "* Indiquer au *profiler* la fin de chaque itération d'apprentissage (avant la validation).\n",
    "\n",
    "\n",
    "* Ajouter des balises comme suit :\n",
    "\n",
    "```python\n",
    "    #TODO tag forward step with record functions\n",
    "    with record_function(\"optimizer zero grad\"): optimizer.zero_grad()\n",
    "    # Implement autocasting\n",
    "    with autocast():\n",
    "        with record_function(\"inference\"): outputs = model(images)\n",
    "        with record_function(\"loss function\"): loss = criterion(outputs, labels)\n",
    "    \n",
    "    if args.test: chrono.backward()       \n",
    "\n",
    "    #TODO tag backward step with record functions\n",
    "    # Implement gradient scaling\n",
    "    with record_function(\"gradient compute\"): scaler.scale(loss).backward()\n",
    "    with record_function(\"optimizer step and weights update\"): scaler.step(optimizer)\n",
    "    with record_function(\"Scaler update\"): scaler.update()\n",
    "```\n",
    "\n",
    "### Génération d'une trace profiler\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "__Remarques__ : \n",
    "* le profilage sera actif sur 5 *steps* donc nous n'exécutons l'entraînement que sur 8 steps grâce à l'argument `--test-nsteps 8`.\n",
    "* Nous lancerons deux *jobs* de prise de trace, avec une taille de *batch* de `512` puis une taille de *batch* de `64`.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = [f'./dlojz1_4.py -b 512 --image-size {image_size} --test --test-nsteps 8',\n",
    "           f'./dlojz1_4.py -b 64 --image-size {image_size} --test --test-nsteps 8']\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['205798', '205799']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : vérifier que 2 traces ont bien été générées dans les répertoires `profiler/<name>_<jobid>_bs512_is224/` et `profiler/<name>_<jobid>_bs64_is224/` et  sous la forme d'un fichier `.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree profiler/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des traces profiler avec TensorBoard <a id=\"visu_tensorboard_gpu\"></a>\n",
    "\n",
    "**TODO** : visualiser cette trace grâce à l'application TensorBoard en suivant les étapes suivantes :\n",
    "* ouvrir [jupyterhub.idris.fr](https://jupyterhub.idris.fr) dans un nouvel onglet du navigateur\n",
    "* ouvrir une nouvelle instance JupyterHub en cliquant sur **Add New JupyterLab Instance**\n",
    "* sélectionner **Spawn server on SLURM node** (on va réserver un GPU)\n",
    "* sélectionner **Tensorboard** dans le menu **Frontend**\n",
    "* définir le chemin des logs **$WORK/DLO-JZ/Jour1/tp_dlojz_jour1/profiler** dans **TensorBoard logs directory**\n",
    "\n",
    "<div><img src=\"images/slurm_spawner_a100_tensorboard.png\" width=\"550\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sélectionner l'option avancée `--partition=Octo-GPU A100 SXM4 with 80 GB GPU mem`\n",
    "\n",
    "<div><img src=\"images/slurm_spawner_a100_tensorboard_advanced.png\" width=\"550\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* lancer l'instance TensorBoard\n",
    "<div><img src=\"images/slurm_spawner_a100_tensorboard_start.png\" width=\"550\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remarque__ : le premier démarrage de TensorBoard peut prendre un peu de temps. Il faut parfois faire preuve d'un peu de patience lorsqu'on utilise cet outil mais ça en vaut la peine :)\n",
    "\n",
    "Vous disposez de **2 traces** : une avec un *batch_size* de **512** et l'autre avec un *batch_size* de **64**.\n",
    "\n",
    "**TODO** : en naviguant dans les différents onglets du TensorBoard, chercher à répondre aux questions suivantes :\n",
    "* Comparer les 2 traces : le GPU est-il bien utilisé ? (mémoire max utilisée, *occupancy*, *efficiency*)\n",
    "* les *TensorCores* sont-ils bien sollicités ? Quelles sont les couches éligibles aux *TensorCores*? (Voir les vue *Operator* et *GPU Kernel*)\n",
    "* essayer de repérer les grandes étapes de calcul sur la *timeline* de l'exécution (onglet *Trace*)\n",
    "\n",
    "**IMPORTANT** : une fois le TP terminé, penser à quitter l'instance JupyterHub pour **libérer le GPU** ( *> Hub Control Panel > Cancel* )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionnel : Profiler la validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : dans le script [dlojz1_4.py](./dlojz1_4.py) :\n",
    "  * Ajouter des balises comme suit :\n",
    "```python\n",
    "    # Runs the forward pass with no grad mode.\n",
    "    with torch.no_grad():\n",
    "        # Implement autocasting\n",
    "        with autocast():\n",
    "            with record_function(\"inference\"): val_outputs = model(val_images)\n",
    "            with record_function(\"loss function\"): val_loss = criterion(val_outputs, val_labels)\n",
    "```\n",
    "  * Enlever l'indication de fin d'itération d'apprentissage.\n",
    "  * A la place, indiquer au *profiler* la fin de chaque itération de validation (dans la boucle de validation).\n",
    "  * Reprendre une trace profiler\n",
    "  * La visualiser sur Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'./dlojz1_4.py -b 512 --image-size {image_size} --test --test-nsteps 8'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['159708']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : dans le script [dlojz1_4.py](./dlojz1_4.py) :\n",
    "* Vous pouvez ensuite changer la valeur de la variable `VAL_BATCH_SIZE=250`\n",
    "* Reprendre une trace profiler\n",
    "* La visualiser sur Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Garage](images/stop.png \"Arrêtez-vous ici! Une présentation vous attend avant le prochain TP.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.3.0_py3.11.5",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-2.3.0_py3.11.5"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
