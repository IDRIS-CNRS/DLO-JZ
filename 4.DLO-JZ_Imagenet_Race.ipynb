{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLO-JZ Imagnet Race - Jour 3 \n",
    "\n",
    "![race](./images/F1.png)\n",
    "\n",
    "\n",
    "Le but de ce TP est de paramétrer l'entraînement pour participer à la course Imagenet Racing.\n",
    "\n",
    "Les *job* de chaque participant durant environ 30 minutes, s'exécuteront pendant la nuit. Les résultats seront commentés le lendemain.\n",
    "\n",
    "Les cellules dans ce *notebook* ne sont pas prévues pour être modifiées, sauf rares exceptions indiquées dans les commentaires. Les TP se feront en modifiant le code `dlojz_imagenetrace.py`.\n",
    " \n",
    "*Notebook rédigé par l'équipe assistance IA de l'IDRIS, juin 2023*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environnement de calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un module PyTorch doit avoir été chargé pour le bon fonctionnement de ce Notebook. **Nécessairement**, le module `pytorch-gpu/py3/1.11.0` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!module list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions *python* de gestion de queue SLURM dévelopées par l'IDRIS et les fonctions dédiées à la formation DLO-JZ sont à importer.\n",
    "\n",
    "Le module d'environnement pour les *jobs* et la taille des images sont fixés pour ce *notebook*.\n",
    "\n",
    "**TODO :** choisir un *pseudonyme* (maximum 5 caractères) pour vous différencier dans la queue SLURM et dans les outils collaboratifs pendant la formation et la compétition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idr_pytools import display_slurm_queue, gpu_jobs_submitter, search_log\n",
    "from dlojz_tools import controle_technique, compare, GPU_underthehood, plot_accuracy, lrfind_plot, imagenet_starter\n",
    "MODULE = 'pytorch-gpu/py3/1.11.0'\n",
    "account = 'for@v100'\n",
    "# TODO\n",
    "name = 'pseudo'   ## Pseudonyme à choisir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation d'un repertoire `checkpoints` si cela n'a pas déjà été fait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion de la queue SLURM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie permet d'afficher et de gérer la queue SLURM.\n",
    "\n",
    "Pour afficher toute la queue *utilisateur* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque**: Cette fonction utilisée plusieurs fois dans ce *notebook* permet d'afficher la queue de manière dynamique, rafraichie toutes les 5 secondes. Cependant elle ne s'arrête que lorsque la queue est vide. Si vous désirez reprendre la main sur le *notebook*, il vous suffira d'arrêter manuellement la cellule avec le bouton *stop*. Cela a bien sûr aucun impact sur le *scheduler* SLURM. Les *jobs* ne seront pas arrêtés.\n",
    "\n",
    "Si vous voulez arrêter des *jobs* dans la queue:\n",
    "* Annuler tous vos *jobs* dans la queue (décommenter la ligne suivante) : `!scancel -u $USER`\n",
    "* Annuler un *job* dans votre queue (décommenter la ligne suivante et ajouter le numéro du *job* à la fin de la ligne)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!scancel -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie *debug* permet d'afficher les fichiers de sortie et les fichiers d'erreur du *job*.\n",
    "\n",
    "Il est nécessaire dans la cellule suivante (en décommentant) d'indiquer le *jobid* correspondant sous le format suivant.\n",
    "\n",
    "***Remarque*** : dans ce notebook, lorsque vous soumettrez un *job*, vous recevrez en retour le numéro du job dans le format suivant : `jobid = ['123456']`. La cellule ci-dessous peut ainsi être facilement actualisée.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobid = ['2088207']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fichier de sortie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat {search_log(contains=jobid[0])[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fichier d'erreur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat {search_log(contains=jobid[0], with_err=True)['stderr'][0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "### Différence entre deux scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le *debug* ou pour comparer son code avec les solutions mises à disposition, la fonction suivante permet d'afficher une page html contenant un différentiel de fichiers texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"dlojz_imagenetrace.py\"\n",
    "s2 = \"./solutions/dlojz2_1.py\"\n",
    "compare(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir le résultat du différentiel de fichiers sur la page suivante (attention au spoil !) :\n",
    "\n",
    "[compare.html](compare.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "\n",
    "## Préparation de votre machine\n",
    "\n",
    "> “Entre trop et trop peu est la juste mesure.” -- Gilles de Noyers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlojz_tools import plot_accuracy, imagenet_starter, plot_time, turbo_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![car](./images/noun-car-repair-32305.png)\n",
    "\n",
    "\n",
    "### 1. Choix des hyper paramètres de l'apprentissage\n",
    "\n",
    "\n",
    "\n",
    "**TODO :** Choisir la *taille de batch par GPU*  `batch_size` et la *taille d'image* `image_size` permettant d'avoir un bon équilibre (d'après votre intuition) entre une taille d'image suffisante et un nombre d'*epochs* suffisant.\n",
    "\n",
    "* Vous devez choisir:\n",
    "  * la taille des images pour l'apprentissage `image_size`\n",
    "  * la *taille de batch par GPU*  `batch_size`\n",
    "\n",
    "Le nombre d'*epochs* auquel vous avez le droit dépend du *Throughput* mesuré pendant le test. Il faudra regarder la dernière ligne du test `Eligible to run X epochs` pour connaître cette mesure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO :** \n",
    "* Veuillez choisir l'**optimizer** que vous souhaitez appliquer selon ce que l'on a vu lors du TP sur les *optimizer* et l'implémenter dans `dlojz_imagenetrace.py` si vous voulez autre chose que *SGD*.\n",
    "* (Optionnel) vous pouvez aussi choisir d'implémenter dans `dlojz_imagenetrace.py` un autre LR Scheduler que le `OneCycle` de `torch` présent actuellement dans le code.\n",
    "* Vous devez ensuite choisir :\n",
    "  * le learning rate maximum `lr`\n",
    "  * la valeur de *weight decay* `weight_decay`\n",
    "  * optionnellement changer la valeur de `momentum`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 176\n",
    "batch_size = 512\n",
    "lr = 2.\n",
    "weight_decay = 5e-4\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (Optionnel) : Ajouter de la Data Augmentation\n",
    "\n",
    "**TODO Optionnel :** \n",
    "Vous pouvez aussi choisir d'ajouter de la *Data Augmentation* dans `dlojz_imagenetrace.py` comme dans le TP de ce matin.\n",
    "\n",
    "* RandAugment\n",
    "* MixUp\n",
    "* CutMix\n",
    "* Autres ...\n",
    "\n",
    "**Remarque** : Si la *Data Augmentation* permet d'atteindre des *scores* de métrique plus élevés, il faudra normalement plus d'*epochs* pour l'atteindre, l'apprentissage sera plus long. Il est donc nécessaire de prévoir une descente de gradient plus agréssive en adaptant la taille d'image, le *batch size*, le *learning rate* et l'*optimizer* ou de prévoir d'utiliser un modèle qui apprend plus vite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. (Optionnel) : Changer de modèle\n",
    "\n",
    "Vous pouvez aussi choisir de changer de modèle.\n",
    "\n",
    "Par exemple, en choisissant un modèle `torchvision` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "print([\n",
    "    k for k, v in models.__dict__.items()\n",
    "    if callable(v) and k[0].islower() and k[0] != \"_\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.wide_resnet50_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of total parameters: {}'.format(sum([p.numel() for p in model.parameters()])))\n",
    "print('number of trainable parameters: {}'.format(sum([p.numel() for p in model.parameters() if p.requires_grad])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple, en choisissant un modèle `timm` :\n",
    "\n",
    "`*resnet*` pour avoir une liste des modèles dont le nom comporte `resnet`. Vous pouvez faire une recherche différente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "timm.list_models('*resnet*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('seresnet50t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of total parameters: {}'.format(sum([p.numel() for p in model.parameters()])))\n",
    "print('number of trainable parameters: {}'.format(sum([p.numel() for p in model.parameters() if p.requires_grad])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO Optionnel :**\n",
    "\n",
    "Si vous choisissez de changer de modèle, il faudra dans `dlojz_imagenetrace.py` :\n",
    "\n",
    "* importer `timm` si vous utilisez la librairie :\n",
    "```python\n",
    "import timm\n",
    "```\n",
    "\n",
    "* charger le modèle choisi et décrire le modèle dans `archi_model` pour les *log WeightandBiases*.\n",
    "\n",
    "par exemple : \n",
    "\n",
    "```python\n",
    "model = models.wide_resnet50_2()\n",
    "model = model.to(gpu)\n",
    "\n",
    "archi_model = 'Wide Resnet-50 2'\n",
    "\n",
    "```\n",
    "\n",
    "ou\n",
    "\n",
    "```python\n",
    "model = timm.create_model('seresnet50t')\n",
    "model = model.to(gpu)\n",
    "\n",
    "archi_model = 'SE Resnet-50 t'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester votre solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f'dlojz_imagenetrace.py -b {batch_size} --image-size {image_size} --lr {lr} --wd {weight_decay} --mom {momentum}  --test'\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optionnel : paramètres d'optimisation du DataLoader\n",
    "\n",
    "Si vous souhaitez appliquer des paramètres du DataLoader différents des paramètres par défaut, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code` et la modifier."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# paramètres d'entrée correspondant aux optimisations du DataLoader\n",
    "command += ' --num-workers 10' \n",
    "command += ' --persistent-workers'\n",
    "command += ' --pin-memory'\n",
    "command += ' --non-blocking'\n",
    "command += ' --prefetch-factor 3'\n",
    "command += ' --no-drop-last'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00', constraint='v100-32g')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Commentaires](images/cedez.png \"Attention une fois sûr de votre solution, vous pouvez lancer un apprentissage complet qui tourbera la nuit\")\n",
    "\n",
    "---------------------------\n",
    "\n",
    "## Apprentissage complet sur 32 GPU (à lancer en toute fin de journée)\n",
    "\n",
    "![race](./images/F1.png)\n",
    "\n",
    "> \"L'important dans la vie, ce n'est point le triomphe, mais le combat. L'essentiel n'est pas d'avoir vaincu, mais de s'être bien battu.\"  -- Pierre de Coubertin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO :** Une fois que vous avez choisi la configuration que vous souhaitez engager pour la course, la fonction suivante permet de générer la bonne commande à soumettre à *SLURM* avec le bon nombre d'*epochs*, les bonnes configurations de *taille de batch par GPU*  et de *taille d'image*, à condition d'avoir fourni le bon `jobid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = imagenet_starter(jobid, jour2=True, lr=lr, moment=momentum, weight_decay=weight_decay)\n",
    "assert command.split()[0] == 'dlojz_imagenetrace.py', \"Veuillez bien mettre l'option jour2=True, svp !!\" \n",
    "command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optionnel : paramètres d'optimisation du DataLoader\n",
    "\n",
    "Si vous souhaitez appliquer des paramètres du DataLoader différents des paramètres par défaut, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code` et la modifier."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# paramètres d'entrée correspondant aux optimisations du DataLoader\n",
    "command += ' --num-workers 10' \n",
    "command += ' --persistent-workers'\n",
    "command += ' --pin-memory'\n",
    "command += ' --non-blocking'\n",
    "command += ' --prefetch-factor 3'\n",
    "command += ' --no-drop-last'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_gpu = 32\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name+'_race',\n",
    "                   account=account, time_max='01:00:00', constraint='v100-32g', slurm_addon='#SBATCH --begin=18:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['91607']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobids = ['1494173', jobid[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(jobids[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time(jobids[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name+'_race')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Votre résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(jobids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publication des Résultats sur WandB\n",
    "\n",
    "Décommenter la ligne `#!wandb sync --sync-all` pour publier les résultats sur le dépôt WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_API_KEY']='2ecf1cc3a3fe45c17b480e66dd0f390c85763d42'\n",
    "#!wandb sync --sync-all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wandb.ai/dlojz/Imagenet%20Race%20Cup?workspace=user-bcabot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-1.11.0_py3.9.12",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-1.11.0_py3.9.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
