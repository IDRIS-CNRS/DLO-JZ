{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLO-JZ Optimiseurs et large batch - Jour 2 \n",
    "\n",
    "Les cellules dans ce *notebook* ne sont pas prévues pour être modifiées, sauf rares exceptions indiquées dans les commentaires. \n",
    "\n",
    "*Notebook rédigé par l'équipe assistance IA de l'IDRIS, octobre 2022*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook est prévu pour être exécuté à partir d'une machine frontale de Jean-Zay. Le *hostname* doit être jean-zay[1-5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un module PyTorch doit avoir été chargé pour le bon fonctionnement de ce Notebook. **Nécessairement**, le module `pytorch-gpu/py3/1.11.0` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!module list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions *python* de gestion de queue SLURM dévelopées par l'IDRIS et les fonctions dédiées à la formation DLO-JZ sont à importer.\n",
    "\n",
    "Le module d'environnement pour les *jobs* et la taille des images sont fixés pour ce *notebook*.\n",
    "\n",
    "**TODO :** choisir un *pseudonyme* (maximum 5 caractères) pour vous différencier dans la queue SLURM et dans les outils collaboratifs pendant la formation et la compétition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idr_pytools import display_slurm_queue, gpu_jobs_submitter, search_log\n",
    "from dlojz_tools_tp import plot_accuracy, lrfind_plot, plot_accuracy_lr\n",
    "MODULE = 'pytorch-gpu/py3/1.11.0'\n",
    "account = 'for@v100'\n",
    "n_gpu = 2\n",
    "\n",
    "name = 'pseudo'  #TODO#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset et modèle\n",
    "\n",
    "Pour ce TP, on va utiliser la base de données CIFAR 10 et le modèle Resnet-18 pour pouvoir faire tourner des entrainements complets en un temps raisonnable. Le TP se fera en modifiant le code `cifar10.py`.\n",
    "\n",
    "### CIFAR 10\n",
    "\n",
    "#### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "        transforms.RandomHorizontalFlip(),              # Horizontal Flip - Data Augmentation\n",
    "        transforms.ToTensor()                          # convert the PIL Image to a tensor\n",
    "        ])\n",
    "    \n",
    "    \n",
    "train_dataset = torchvision.datasets.CIFAR10(root=os.environ['ALL_CCFRSCRATCH']+'/CIFAR_10',\n",
    "                                             train=True, download=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,    \n",
    "                                           batch_size=4,\n",
    "                                           shuffle=True)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print('X train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[0].shape, batch[0].dtype, batch[0].element_size()*batch[0].nelement()))\n",
    "print('Y train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[1].shape, batch[1].dtype, batch[1].element_size()*batch[1].nelement()))\n",
    "\n",
    "img = batch[0][0].numpy().transpose((1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "_ = plt.title('label class: {}'.format(batch[1][0].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose([\n",
    "                    transforms.ToTensor()                           # convert the PIL Image to a tensor\n",
    "                    ])\n",
    "    \n",
    "val_dataset = torchvision.datasets.CIFAR10(root=os.environ['ALL_CCFRSCRATCH']+'/CIFAR_10',\n",
    "                                               train=False, download=False, transform=val_transform)\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()\n",
    "print('number of total parameters: {}'.format(sum([p.numel() for p in model.parameters()])))\n",
    "print('number of trainable parameters: {}'.format(sum([p.numel() for p in model.parameters() if p.requires_grad])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Description\n",
    "\n",
    "Nous étudierons 4 *optimizer* (SGD, AdamW, LAMB et LARS).\n",
    "\n",
    "A chaque fois nous regarderons le cas d'un apprentissage **Small Batch** et le cas d'un apprentissage **Large Batch**.\n",
    "\n",
    " * **Small Batch** : *Global Batch Size* de **256** sur 2 GPU sur **30** *epochs*\n",
    " * **Large Batch** : *Global Batch Size* de **8192** sur 2 GPU sur **50** *epochs* \n",
    "\n",
    "\n",
    "**Remarque** : \n",
    "\n",
    "Le paramètre *wrapped_optimizer* est présent dans le code à cause de l'implémentation de LARS spécifiquement. Car le *LR scheduler* doit prendre en entrée l'*optimizer SGD* de base non *wrapped*. \n",
    "\n",
    "Pour les autres *optimizers*, il ne sert à rien. Mais cette astuce permet de basculer sur chaque type d'*optimizer* facilement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LR Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le but d'utiliser un *Cycle Scheduler*, il nous faut d'abord trouver l'intervalle des valeurs du *learning rate* qui auront un effet positif sur l'apprentissage du modèle.\n",
    "\n",
    "On va lancer le script 'cifar10.py' avec l'option `--findlr` ce qui va lancer l'entrainement sur quelques *epochs* durant lesquelles le *learning rate* va doucement augmenter.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = [f'cifar10.py -b 128 -e 10 --findlr --lr 5.', \n",
    "           f'cifar10.py -b 4096 -e 20 --findlr --lr 5.']\n",
    "jobid_sgd_lrf = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid_sgd_lrf = {jobid_sgd_lrf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid_sgd_lrf = ['228509', '228510']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant tracer la courbe de la *loss* en fonction du *learning rate*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfind_plot(jobid_sgd_lrf[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La courbe transparente représente les valeurs réelles, la courbe opaque représente un lissage de ces valeurs.\n",
    "\n",
    "À partir de cette courbe, vous pouvez trouver les valeurs minimale et maximale acceptables du *learning rate*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfind_plot(jobid_sgd_lrf[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TP_opti_0 : *Learning Rate* constant (référence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va lancer un entrainement de référence avec un *learning rate* constant.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`.\n",
    "\n",
    "**TODO : remplacer XXX par la valeur de *learning rate* choisie**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr = XXX\n",
    "command = f'cifar10.py -b 128 -e 30 --wd 5e-3 --lr {lr}'\n",
    "jobid1 = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid1 = {jobid1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid1 = ['228535']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobids=[jobid1]\n",
    "plot_accuracy_lr(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TP_opti_1 : *One Cycle Learning Rate*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant modifier le code pour remplacer le *learning rate* constant par un *One Cycle Scheduler* et comparer le résultat avec l'entrainement de référence.\n",
    "\n",
    "**TODO** : dans le script `cifar10.py`:\n",
    "* Trouver la ligne de déclaration du *Learning Rate Scheduler* :\n",
    "\n",
    "```python\n",
    "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer, factor=1, total_iters=5)\n",
    "```\n",
    "* Le remplacer par un *One Cycle Scheduler* \n",
    "\n",
    "```python\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=args.lr, steps_per_epoch=N_batch, epochs=args.epochs)\n",
    "```\n",
    "\n",
    "__Remarque__ : Le *OneCycleLR* de PyTorch calcule automatiquement une valeur minimale de *learning rate* à partir de la valeur maximale donnée.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`.\n",
    "\n",
    "**TODO : remplacer XXX par les valeurs maximales de *learning rate* choisies (Small Batch et Large Batch)**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr_smallb = XXX\n",
    "lr_largeb = XXX\n",
    "command = [f'cifar10.py -b 128 -e 30 --wd 5e-3 --lr {lr_smallb}', \n",
    "           f'cifar10.py -b 4096 -e 50 --wd 5e-3 --lr {lr_largeb}']\n",
    "jobid_sgd = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid_sgd = {jobid_sgd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid_sgd = ['228548', '228549']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez comparer les courbes de *test accuracy* et de *learning rate* avec l'entrainement de référence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobids=[jobid1, jobid_sgd[:1]]\n",
    "plot_accuracy_lr(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TP_opti_2 : Optimiseur *AdamW*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant modifier l'optimiseur pour utiliser *AdamW*.\n",
    "\n",
    "**TODO** : dans le script `cifar10.py`:\n",
    "* Trouver la ligne de déclaration de l'optimiseur *Stochastic Gradient Descent* :\n",
    "\n",
    "```python\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr, momentum=args.mom, weight_decay=args.wd)\n",
    "```\n",
    "* Le remplacer par l'optimiseur *Adam* :\n",
    "\n",
    "```python\n",
    "optimizer = torch.optim.AdamW(model.parameters(), args.lr, betas=(args.mom, 0.999), weight_decay=args.wd)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'optimiseur ayant changé il nous faut recalculer la valeur de *learning rate* maximale à donner en paramètre :\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = [f'cifar10.py -b 128 -e 10 --findlr --lr 5.', \n",
    "           f'cifar10.py -b 4096 -e 20 --findlr --lr 5.']\n",
    "jobid_adam_lrf = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid_adam_lrf = {jobid_adam_lrf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid_adam_lrf = ['228561', '228562']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfind_plot(jobid_adam_lrf[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfind_plot(jobid_adam_lrf[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant lancer l'entrainement avec l'optimiseur *AdamW*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`.\n",
    "\n",
    "**TODO : remplacer XXX par les valeurs maximales de *learning rate* choisies (Small Batch et Large Batch)**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr_smallb = XXX\n",
    "lr_largeb = XXX\n",
    "command = [f'cifar10.py -b 128 -e 30 --wd 1e-2 --lr {lr_smallb}', \n",
    "           f'cifar10.py -b 4096 -e 50 --wd 1e-2 --lr {lr_largeb}']\n",
    "jobid_adamw = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid_adamw = {jobid_adamw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid_adamw = ['228564', '228565']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez comparer les courbes de *test accuracy* et de *train accuracy* avec les entrainements précédents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobids=[jobid_sgd[:1], jobid_adamw[:1]]\n",
    "plot_accuracy(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobids=[jobid_sgd[1:], jobid_adamw[1:]]\n",
    "plot_accuracy(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TP_opti_3 : Optimiseur *LAMB*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant modifier l'optimiseur pour utiliser *LAMB*.\n",
    "\n",
    "**TODO** : dans le script `cifar10.py`:\n",
    "* Remplacer l'optimiseur *AdamW* par l'optimiseur *LAMB* :\n",
    "\n",
    "```python\n",
    "optimizer = apex.optimizers.FusedLAMB(model.parameters(), args.lr, betas=(args.mom, 0.999), weight_decay=args.wd)\n",
    "```\n",
    "\n",
    "Il faut maintenant à nouveau toruver la valeur de *learning rate* maximale à donner en paramètre pour cet optimiseur :\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = [f'cifar10.py -b 128 -e 10 --findlr --lr 5.', \n",
    "           f'cifar10.py -b 4096 -e 20 --findlr --lr 5.']\n",
    "jobid_lamb_lrf = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid_lamb_lrf = {jobid_lamb_lrf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid_lamb_lrf = ['228608', '228609']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfind_plot(jobid_lamb_lrf[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfind_plot(jobid_lamb_lrf[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant lancer l'entrainement avec l'optimiseur LAMB.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`.\n",
    "\n",
    "**TODO : remplacer XXX par les valeurs maximales de *learning rate* choisies (Small Batch et Large Batch)**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr_smallb = XXX\n",
    "lr_largeb = XXX\n",
    "command = [f'cifar10.py -b 128 -e 30 --wd 1e-1 --lr {lr_smallb}', \n",
    "           f'cifar10.py -b 4096 -e 50 --wd 1e-1 --lr {lr_largeb}']\n",
    "jobid_lamb = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid_lamb = {jobid_lamb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid_lamb = ['228610', '228612']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez comparer les courbes de *test accuracy* et de *train accuracy* avec les entrainements précédents.\n",
    "\n",
    "#### Small Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobids=[jobid_sgd[:1], jobid_adamw[:1], jobid_lamb[:1]]\n",
    "plot_accuracy(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobids=[jobid_sgd[1:], jobid_adamw[1:], jobid_lamb[1:]]\n",
    "plot_accuracy(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TP_opti_4 : Optimiseur *LARS*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour finir nous allons essayer un entrainement large batch avec l'optimiseur LARS ou LARC (optimisation apex de LARS)\n",
    "\n",
    "**TODO** : dans le script `cifar10.py`:\n",
    "* Remplacer l'optimiseur *LAMB* par l'optimiseur *LARC* :\n",
    "\n",
    "```python\n",
    "optimizer = ...\n",
    "\n",
    "wrapped_optimizer = optimizer\n",
    "```\n",
    "par\n",
    "\n",
    "```python\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr, momentum=args.mom, weight_decay=args.wd)\n",
    "    \n",
    "wrapped_optimizer = LARC(optimizer)\n",
    "```\n",
    "\n",
    "Il faut maintenant à nouveau trouver la valeur de *learning rate* maximale à donner en paramètre pour cet optimiseur :\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = [f'cifar10.py -b 128 -e 10 --findlr --lr 5.', \n",
    "           f'cifar10.py -b 4096 -e 20 --findlr --lr 5.']\n",
    "jobid_lars_lrf = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid_lars_lrf = {jobid_lars_lrf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid_lars_lrf = ['228624', '228625']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfind_plot(jobid_lars_lrf[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfind_plot(jobid_lars_lrf[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant lancer l'entrainement avec l'optimiseur LARS.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`.\n",
    "\n",
    "**TODO : remplacer XXX par les valeurs maximales de *learning rate* choisies (Small Batch et Large Batch)**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr_smallb = XXX\n",
    "lr_largeb = XXX\n",
    "command = [f'cifar10.py -b 128 -e 30 --wd 5e-3 --lr {lr_smallb}', \n",
    "           f'cifar10.py -b 4096 -e 50 --wd 5e-3 --lr {lr_largeb}']\n",
    "jobid_lars = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid_lars = {jobid_lars}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid_lars = ['228631', '228633']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez comparer les courbes de *test accuracy* et de *train accuracy* avec les entrainements précédents.\n",
    "\n",
    "#### Small Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobids=[jobid_sgd[:1], jobid_adamw[:1], jobid_lamb[:1], jobid_lars[:1]]\n",
    "plot_accuracy(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobids=[jobid_sgd[1:], jobid_adamw[1:], jobid_lamb[1:], jobid_lars[1:]]\n",
    "plot_accuracy(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## &#x2622; ⚠ Bonus expérimental ⚠ &#x2622; \n",
    "## TP_opti_5 : Optimiseur *LION* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section bonus, nous allons tester un optimiseur relativement récent : LION.\n",
    "\n",
    "Il s'agit d'un optimiseur issue de la publication : Symbolic Discovery of Optimization Algorithms, https://arxiv.org/abs/2302.06675\n",
    "\n",
    "**TODO** : dans le script `cifar10.py`:\n",
    "* Remplacer l'optimiseur *LARC* par l'optimiseur *LION* :\n",
    "\n",
    "```python\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr, momentum=args.mom, weight_decay=args.wd)\n",
    "\n",
    "wrapped_optimizer = LARC(optimizer)\n",
    "```\n",
    "par\n",
    "\n",
    "```python\n",
    "optimizer = Lion(model.parameters(), lr=args.lr, weight_decay=args.wd)\n",
    "    \n",
    "wrapped_optimizer = optimizer\n",
    "```\n",
    "\n",
    "Il faut maintenant à nouveau trouver la valeur de *learning rate* maximale à donner en paramètre pour cet optimiseur :\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = [f'cifar10.py -b 128 -e 10 --findlr --lr 5.', \n",
    "           f'cifar10.py -b 4096 -e 20 --findlr --lr 5.']\n",
    "jobid_lion_lrf = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid_lion_lrf = {jobid_lion_lrf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid_lion_lrf = ['228681', '228682']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Small Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfind_plot(jobid_lion_lrf[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfind_plot(jobid_lion_lrf[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En complément du *learning rate scheduler*, voici quelques indications des auteurs de l'article :**\n",
    "> *Based on our experience, a suitable learning rate for Lion is typically 3-10x smaller than that for AdamW. Since the effective weight decay is lr * λ, the value of decoupled weight decay λ used for Lion is 3-10x larger than that for AdamW in order to maintain a similar strength.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant lancer l'entrainement avec l'optimiseur LION.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`.\n",
    "\n",
    "**TODO : remplacer XXX par les valeurs maximales de *learning rate* choisies (Small Batch et Large Batch). \n",
    "Vous devrez aussi définir les valeurs de *weight decay* pour chaque taille de batch.** \n",
    "\n",
    "**Pour les relativement petits batchs, vous devriez pouvoir obtenir de bonnes performances en vous servant du learning rate finder et des conseils des auteurs**\n",
    "\n",
    "**Le cas des larges batchs n'est pas aussi trivial. Lors de nos tests, nous n'avons pas pu identifier des paramètres véritablement plus efficaces.**\n",
    "\n",
    "**Vous pouvez commencer avec le même *learning rate scheduler* qu'avant mais nous vous invitons vivement à expérimenter des changements dessus.**\n",
    "\n",
    "\n",
    "**TODO** :  dans le script `cifar10.py`:\n",
    "* Changer le learning rate scheduler par un CosineAnnealingLR pour lequel le comportement de LION est plus régulier.\n",
    "\n",
    "```python\n",
    "scheduler = ...\n",
    "```\n",
    "par\n",
    "\n",
    "```python\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                                       T_max=N_batch*args.epochs, \n",
    "                                                       eta_min=args.lr/5) \n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr_smallb = XXX\n",
    "lr_largeb = XXX\n",
    "wd_smallb = XXX\n",
    "wd_largeb = XXX\n",
    "command = [f'cifar10.py -b 128 -e 30 --wd {wd_smallb} --lr {lr_smallb}', \n",
    "           f'cifar10.py -b 4096 -e 50 --wd {wd_largeb} --lr {lr_largeb}']\n",
    "jobid_lion = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid_lion = {jobid_lion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid_lion = ['228705', '228706']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez comparer les courbes de *test accuracy* et de *train accuracy* avec les entrainements précédents.\n",
    "\n",
    "#### Small Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobids=[jobid_sgd[:1], jobid_adamw[:1], jobid_lamb[:1], jobid_lars[:1], jobid_lion[:1]]\n",
    "plot_accuracy(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobids=[jobid_sgd[1:], jobid_adamw[1:], jobid_lamb[1:], jobid_lars[1:], jobid_lion[1:]]\n",
    "plot_accuracy(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "--------------\n",
    "\n",
    "## Annexe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec l'*optimizer* de votre choix (Il faudra modifier le code en fonction) :\n",
    "\n",
    "Vous pouvez faire d'autres tests en jouant sur les différents paramètres :\n",
    "* Nombre d'epoch\n",
    "* La valeur du *weight decay*\n",
    "* La valeur du *learning rate*\n",
    "* La taille de batch. Attention : **sur 2 GPU**, donc la taille de *batch* sera **multipliée par 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = \n",
    "weight_decay = \n",
    "lr = \n",
    "batch_size = \n",
    "command = f'cifar10.py -b {batch_size} -e {n_epoch} --wd {weight_decay} --lr {lr}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR finder (Optionnel)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command_lr = f'cifar10.py -b {batch_size} -e 20 --findlr --lr 5. --wd {weight_decay}'\n",
    "jobid_test_lrf = gpu_jobs_submitter(command_lr, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid_test_lrf = {jobid_test_lrf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid_test_lrf ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfind_plot(jobid_test_lrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apprentissage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jobid_test = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                   account=account, time_max='00:10:00')\n",
    "print(f'jobid_test = {jobid_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid_test = ['428']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(jobid_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-1.11.0_py3.9.12",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-1.11.0_py3.9.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
