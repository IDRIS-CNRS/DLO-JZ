{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLO-JZ Data Augmentation - Jour 4 \n",
    "\n",
    "![car](./images/noun-car-repair-32305.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objet du notebook\n",
    "\n",
    "Dans ce TP, on se focalise sur les **problématiques de performance liées à la *Data Augmentation***. \n",
    "\n",
    "Les opérations de transformation des données d'entrée se font en général sur le CPU. On verra dans ce TP qu'il est possible de les déléguer au GPU si les ressources de calcul offertes par le CPU ne sont pas suffisantes.\n",
    "\n",
    "Ce TP est divisé en trois parties, correspondant à trois types d'augmentation de données à implémenter :\n",
    "\n",
    "* **TP 1** : RandAugment sur CPU\n",
    "* **TP 2** : mixup sur CPU et GPU\n",
    "* **TP 3** : CutMix sur GPU\n",
    "\n",
    "\n",
    "Les cellules dans ce *notebook* ne sont pas prévues pour être modifiées, sauf rares exceptions indiquées dans les commentaires. Les TP se feront en modifiant les codes `dlojz_da_X.py`.\n",
    "\n",
    "Les directives de modification seront marquées par l'étiquette **TODO** dans le *notebook* suivant.\n",
    " \n",
    "Les solutions sont présentes dans le répertoire `solutions/`.\n",
    "\n",
    "*Notebook rédigé par l'équipe assistance IA de l'IDRIS, février 2024*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environnement de calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions *python* de gestion de queue SLURM dévelopées par l'IDRIS et les fonctions dédiées à la formation DLO-JZ sont à importer.\n",
    "\n",
    "Le module d'environnement pour les *jobs* et la taille des images sont fixés pour ce *notebook*.\n",
    "\n",
    "**TODO :** choisir un *pseudonyme* (maximum 5 caractères) pour vous différencier dans la queue SLURM et dans les outils collaboratifs pendant la formation et la compétition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from idr_pytools import display_slurm_queue, gpu_jobs_submitter, search_log\n",
    "from dlojz_tools import controle_technique, compare, GPU_underthehood, plot_accuracy, lrfind_plot, imagenet_starter, turbo_profiler\n",
    "MODULE = 'pytorch-gpu/py3/2.3.0'\n",
    "account = 'for@a100'\n",
    "name = 'pseudo'   ## Pseudonyme à choisir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion de la queue SLURM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour afficher vos jobs dans la queue SLURM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque**: Cette fonction est utilisée plusieurs fois dans ce *notebook*. Elle permet d'afficher la queue de manière dynamique, rafraichie toutes les 5 secondes. Elle ne s'arrête que lorsque la queue est vide. Si vous désirez reprendre la main sur le *notebook*, il vous suffira d'arrêter manuellement la cellule avec le bouton *stop*. Cela a bien sûr aucun impact les jobs soumis.\n",
    "\n",
    "Si vous voulez retirer TOUS vos jobs de la queue SLURM, décommenter et exécuter la cellule suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!scancel -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous voulez retirer UN de vos jobs de la queue SLURM, décommenter, compléter et exécuter la cellule suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!scancel <jobid>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "### Différence entre deux scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour comparer son code avec les solutions mises à disposition, la fonction suivante permet d'afficher une page html contenant un différentiel de fichiers texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s1 = \"dlojz_da_2.py\"\n",
    "s2 = \"./solutions/dlojz_da_2.py\"\n",
    "#s1 = \"mixup.py\"\n",
    "#s2 = \"solutions/mixup-solution.py\"\n",
    "compare(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir le résultat du différentiel de fichiers sur la page suivante (attention au spoil !) :\n",
    "\n",
    "[compare.html](compare.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## Garage - Mise à niveau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fixe le *batch size* et la taille d'image pour ce TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs_optim = 512\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP_DA_1 : RandAugment\n",
    "\n",
    "Le but de ce TP est d'ajouter la transformation `RandAugment` (disponible dans *torchvision*) dans la liste des transformations pour la *Data Augmentation* et de mesurer son impact sur la performance du code.\n",
    "\n",
    "Voir la [documentation torchvision sur RandAugment](https://pytorch.org/vision/stable/generated/torchvision.transforms.RandAugment.html).\n",
    "\n",
    "Vous pouvez exécuter les cellules suivantes pour observer l'effet de la transformation `RandAugment` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "        transforms.RandomResizedCrop(image_size),  # Random resize - Data Augmentation\n",
    "        transforms.RandomHorizontalFlip(),  # Horizontal Flip - Data Augmentation\n",
    "        transforms.RandAugment(5, 9),       # Random Augmentation 5: n operations, 9 : magnitude \n",
    "        transforms.ToTensor()               # convert the PIL Image to a tensor\n",
    "        ])\n",
    "    \n",
    "    \n",
    "train_dataset = torchvision.datasets.ImageNet(root=os.environ['ALL_CCFRSCRATCH']+'/imagenet',\n",
    "                                                  transform=transform)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,    \n",
    "                                           batch_size=4,\n",
    "                                           shuffle=True)\n",
    "batch = next(iter(train_loader))\n",
    "print('X train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[0].shape, batch[0].dtype, batch[0].element_size()*batch[0].nelement()))\n",
    "print('Y train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[1].shape, batch[1].dtype, batch[1].element_size()*batch[1].nelement()))\n",
    "\n",
    "for i in range(4):\n",
    "    img = batch[0][i].numpy().transpose((1,2,0))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation RandAugment sur CPU\n",
    "\n",
    "**TODO :** dans le script [dlojz_da_1.py](dlojz_da_1.py) :\n",
    "* Rajouter la transformation `RandAugment` dans la liste des transformations des images pour le *training* avec le paramétrage suivant : **Nombre d'opérations = 5, Magnitude = 9**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'dlojz_da_1.py -b {bs_optim} --image-size {image_size} --test'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'éviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['887754']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Commentaires](images/cedez.png \"Assurez-vous que tout se passe bien avant de continuer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP_DA_2 : mixup\n",
    "\n",
    "Le but de ce TP est de :\n",
    "* appliquer la transformation `mixup` et mesurer son impact sur la performance du code ;\n",
    "* porter la transformation sur GPU.\n",
    "\n",
    "La transformation `mixup` n'est pas disponible dans *torchvision*, la fonction est disponible dans le script [mixup.py](mixup.py). On notera que cette transformation impacte à la fois l'image et le *label*.\n",
    "\n",
    "On choisira, comme cela est fait habituellement, de *mixer* 2 images présentes dans le *batch* généré par le *DataLoader*. Donc cette transformation sera faite dans la boucle d'apprentissage après génération du *batch* et après toute autre transformation liée à la *Data Augmentation*.\n",
    "\n",
    "Vous pouvez exécuter les cellules suivantes pour observer l'effet de la transformation `mixup` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "        transforms.RandomResizedCrop(image_size),  # Random resize - Data Augmentation\n",
    "        transforms.RandomHorizontalFlip(),  # Horizontal Flip - Data Augmentation\n",
    "        transforms.ToTensor()               # convert the PIL Image to a tensor\n",
    "        ])\n",
    "    \n",
    "    \n",
    "train_dataset = torchvision.datasets.ImageNet(root=os.environ['ALL_CCFRSCRATCH']+'/imagenet',\n",
    "                                                  transform=transform)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mixup import mixup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,    \n",
    "                                           batch_size=16,\n",
    "                                           shuffle=True)\n",
    "batch = next(iter(train_loader))\n",
    "print('X train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[0].shape, batch[0].dtype, batch[0].element_size()*batch[0].nelement()))\n",
    "print('Y train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[1].shape, batch[1].dtype, batch[1].element_size()*batch[1].nelement()))\n",
    "\n",
    "imgs, targets = batch\n",
    "imgs, targets = mixup_data(imgs, targets, num_classes=1000, alpha=2)        ## Transformation mixup\n",
    "\n",
    "for i in range(4):\n",
    "    img = imgs[i].numpy().transpose((1,2,0))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(f'target : {torch.max(targets, dim=1)[1][i]}, lambda : {torch.max(targets, dim=1)[0][i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paramètre alpha pour la beta distribution**\n",
    "\n",
    "Dans le script `mixup.py`, la variable `_lambda` correspond à la proportion conservée de la première image. Elle est choisie aléatoirement suivant une **distribution bêta** définie sur [0, 1].\n",
    "\n",
    "Le paramètre `alpha` agit sur la forme de la distribution bêta. `alpha = 1` correspond à une distribution uniforme, `alpha < 1` favorise un tirage au sort de valeurs proches des bornes `0.` ou `1.`, et  `alpha > 1` favorise un tirage au sort de valeurs proches du centre `0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for alpha in [0.5, 1., 2.]:\n",
    "    plt.hist(np.random.beta(alpha, alpha, 1000000), bins=50, density=True, histtype='step')\n",
    "    plt.title(f'alpha={alpha}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation mixup sur CPU\n",
    "\n",
    "**TODO :** dans le script [dlojz_da_2.py](dlojz_da_2.py) :\n",
    "* Importer la transformation `mixup`\n",
    "```python\n",
    "from mixup import mixup_data\n",
    "```\n",
    "\n",
    "* Rajouter la transformation `mixup` dans la boucle d'apprentissage **avant** d'envoyer le *batch* d'images et de *labels* au GPU, avec le paramétrage : **num_classes=1000, alpha=2**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'dlojz_da_2.py -b {bs_optim} --image-size {image_size} --test'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'éviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['887894']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation mixup sur GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO :** dans le script [dlojz_da_2.py](dlojz_da_2.py) :\n",
    "* Appliquer la transformation `mixup` dans la boucle d'apprentissage **après** avoir envoyé le *batch* d'images et de *labels* au GPU, avec le paramétrage : **num_classes=1000, alpha=2, device=gpu**.\n",
    "\n",
    "**TODO :** dans le script [mixup.py](mixup.py) :\n",
    "* Ajouter le paramètre `device=device` à chaque fois que l'on crée un nouveau *Tensor* pour qu'il soit stocké en mémoire au bon emplacement (CPU ou GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'dlojz_da_2.py -b {bs_optim} --image-size {image_size} --test'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'éviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['887909']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Commentaires](images/cedez.png \"Assurez-vous que tout se passe bien avant de continuer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP_DA_3 : CutMix\n",
    "\n",
    "Le but de ce TP est de :\n",
    "* appliquer la transformation `CutMix` et mesurer son impact sur la performance du code ;\n",
    "* adapter l'implémentation de la tranformation `CutMix` au calcul GPU.\n",
    "\n",
    "La transformation `CutMix` n'est pas disponible dans *torchvision*, la fonction est disponible dans le script [cutmix.py](cutmix.py). On notera que cette transformation impacte à la fois l'image et le *label*.\n",
    "\n",
    "On choisira, comme cela est fait habituellement, de *mixer* 2 images présentes dans le *batch* généré par le dataloader. Donc cette transformation sera faite dans la boucle d'apprentissage après génération du *batch* et donc après toute autre transformation liée à la *Data Augmentation*.\n",
    "\n",
    "Dans le script `cutmix.py`, la variable `_lambda` correspond à la proportion conservée de la première image. Elle est choisie aléatoirement suivant une **distribution uniforme** définie sur [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "        transforms.RandomResizedCrop(image_size),  # Random resize - Data Augmentation\n",
    "        transforms.RandomHorizontalFlip(),  # Horizontal Flip - Data Augmentation\n",
    "        transforms.ToTensor()               # convert the PIL Image to a tensor\n",
    "        ])\n",
    "    \n",
    "    \n",
    "train_dataset = torchvision.datasets.ImageNet(root=os.environ['ALL_CCFRSCRATCH']+'/imagenet',\n",
    "                                                  transform=transform)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cutmix import cutmix_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,    \n",
    "                                           batch_size=16,\n",
    "                                           shuffle=True)\n",
    "batch = next(iter(train_loader))\n",
    "print('X train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[0].shape, batch[0].dtype, batch[0].element_size()*batch[0].nelement()))\n",
    "print('Y train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[1].shape, batch[1].dtype, batch[1].element_size()*batch[1].nelement()))\n",
    "\n",
    "imgs, targets = batch\n",
    "imgs, targets = cutmix_data(imgs, targets, num_classes=1000)\n",
    "\n",
    "for i in range(4):\n",
    "    img = imgs[i].numpy().transpose((1,2,0))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(f'target : {torch.max(targets, dim=1)[1][i]}, lambda : {torch.max(targets, dim=1)[0][i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation CutMix sur GPU\n",
    "\n",
    "**TODO :** dans le script [dlojz_da_3.py](dlojz_da_3.py) :\n",
    "* Importer la transformation `CutMix`\n",
    "```python\n",
    "from cutmix import cutmix_data\n",
    "```\n",
    "\n",
    "* Rajouter la transformation `CutMix` dans la boucle d'apprentissage **après** avoir envoyé le *batch* d'images et de *labels* au GPU, avec le paramétrage : **num_classes=1000, device=gpu**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'dlojz_da_3.py -b {bs_optim} --image-size {image_size} --test'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'éviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['887951']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation de la transformation CutMix\n",
    "Le code précédent traite les images du *batch* une par une, de manière séquentielle (boucle `for`) :\n",
    "\n",
    "```python\n",
    "mixed_x = x\n",
    "for i in range(len(mixed_x)): # loop over images\n",
    "            mixed_x[i,:,x1[i]:x2[i],y1[i]:y2[i]] = x[s_index[i],:,x1[i]:x2[i],y1[i]:y2[i]]\n",
    "```\n",
    "\n",
    "Le but de cette partie est d'optimiser le code de *CutMix* en générant davantage de parallélisme pour profiter du GPU. Il s'agit de supprimer la boucle `for` et de manipuler directement des batches de tenseurs.\n",
    "\n",
    "Le travail va porter sur la définition de deux **batches de masques** `mask_int` et `mask_ext` de taille `[batch_size,n_channels,weight,height]` que l'on appliquera de la manière suivante : \n",
    "\n",
    "```python\n",
    "mixed_x = mask_ext * x + mask_int * x[s_index, :]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction à implémenter est la suivante :\n",
    "```python\n",
    "def cut_mask(x1, x2, y1, y2, batch_size, W, H, device=None):\n",
    "    \n",
    "    ### TODO\n",
    "    mask_ext, mask_int = None, None\n",
    "    \n",
    "    return mask_ext, mask_int\n",
    "```\n",
    "\n",
    "Arguments :\n",
    "* `x1` : vecteur de longueur `batch_size` avec la coordonnée **min** dans la **largeur** pour chaque image du batch\n",
    "* `x2` : vecteur de longueur `batch_size` avec la coordonnée **max** dans la **largeur** pour chaque image du batch\n",
    "* `y1` : vecteur de longueur `batch_size` avec la coordonnée **min** dans la **hauteur** pour chaque image du batch\n",
    "* `y2` : vecteur de longueur `batch_size` avec la coordonnée **max** dans la **hauteur** pour chaque image du batch\n",
    "* `batch_size` : nombre d'images dans le batch\n",
    "* `W` : largeur des images\n",
    "* `H` : hauteur des images\n",
    "* `device` : unité de calcul ('cpu' ou 'gpu')\n",
    "\n",
    "Retours:\n",
    "* `mask_ext` : tenseur de taille `[batch_size,n_channels,weight,height]` contenant la valeur `False` ou `0` à l'intérieur de la fenêtre et `True` ou `1` à l'extérieur\n",
    "* `mask_int` : tenseur de taille `[batch_size,n_channels,weight,height]` contenant la valeur `True` ou `1` à l'intérieur de la fenêtre et `False` ou `0` à l'extérieur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Création d'un batch de masques**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, pour comprendre la procédure, nous travaillerons avec un *batch* de 3 images de taille `32x32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "batch_size = 3\n",
    "W = 32\n",
    "H = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En entrée, on connait les coordonnées des coins de la fenêtre pour chaque image du *batch* (voir illustration ci-dessous). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# coordonnee min dans la largeur pour chaque image du batch\n",
    "x1 = torch.Tensor([10, 5, 23]).int()\n",
    "# coordonne max dans la largeur pour chaque image du batch\n",
    "x2 =  torch.Tensor([20, 25, 31]).int()\n",
    "# coordonnee min dans la hauteur pour chaque image du batch\n",
    "y1 =  torch.Tensor([5, 10, 0]).int()\n",
    "# coordonne max dans la hauteur pour chaque image du batch\n",
    "y2 =  torch.Tensor([10, 22, 20]).int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><img src=\"./images/cutmix_opt.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Création de w_int et h_int**\n",
    "\n",
    "Pour construire `mask_int`, on va d'abord créer un batch de vecteurs ligne \"largeur\" `w_int` et un batch de vecteurs colonne \"hauteur\" de masques `h_int` (voir illustration ci-dessus).\n",
    "\n",
    "Variables utiles : `batch_size`, `W`, `H`, `x1`, `x2`, `y1`, `y2`.\n",
    "\n",
    "Voir la documentation PyTorch pour la manipulation de tenseurs : [documentation torch](https://pytorch.org/docs/stable/index.html).\n",
    "\n",
    "**Résultats attendus :** (voir illustration ci-dessous)\n",
    "* un batch de vecteurs ligne \"largeur\" `w_int`, tenseur de taille `[3, 1, 32]` contenant des `True` ou `1` si **`x1 ⩽ x ⩽ x2`**, `False` ou `0` sinon \n",
    "* un batch de vecteurs colonne \"hauteur\" `h_int`, tenseur de taille `[3, 32, 1]` contenant des `True` ou `1` si **`y1 ⩽ y ⩽ y2`**, `False` ou `0` sinon \n",
    "![résultat](images/resultat_cutmix.png \"w_int torch.Size([3, 1, 32]) / h_int torch.Size([3, 32, 1])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<details>\n",
    "\n",
    "<summary>Pistes de solutions</summary>\n",
    "    \n",
    "Nous avons trouvé 2 solutions pour résoudre ce problème.\n",
    "\n",
    "* En utilisant la fonction [torch.logical_and](https://pytorch.org/docs/stable/generated/torch.logical_and.html) : il s'agit d'initialiser des tenseurs à `[x, x=0,...,31]` (respectivement `[y, y=0,...,31]`) et d'utiliser `torch.logical_and()` pour appliquer les conditions `x1 ⩽ x and x ⩽ x2` (respectivement `y1 ⩽ y and y ⩽ y2`). Le résultat est un tenseur contenant des opérateurs logiques `True` et `False`.\n",
    "\n",
    "* En utilisant la fonction [torch.cumsum](https://pytorch.org/docs/stable/generated/torch.cumsum.html) : les tenseurs sont initialisés à `0`, on donne la valeur `1` au `x1`ème élément (respectivement `y1`ème), la valeur `-1` au `x2`ème élément (respectivement `y2`ème), puis on utilise la fonction `torch.cumsum` pour faire la somme cumulée des éléments. On obtient un tenseur contenant des `0` et des `1`.\n",
    "\n",
    "Dans tous les cas, il faudra jouer avec les dimensions des tenseurs. Les fonctions utiles sont : [torch.arange()](https://pytorch.org/docs/stable/generated/torch.arange.html), [.size()](https://pytorch.org/docs/stable/generated/torch.Tensor.size.html), [.repeat()](https://pytorch.org/docs/stable/generated/torch.Tensor.repeat.html#torch.Tensor.repeat), [.view()](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html#torch.Tensor.view), [.unsqueeze()](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html#torch-unsqueeze), [.zeros()](https://pytorch.org/docs/stable/generated/torch.zeros.html), ...\n",
    "    \n",
    "Il existe certainement d'autres solutions.\n",
    "    \n",
    "**Rappel** : ne jamais utiliser de `for` nulle part !\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w_int = #TODO\n",
    "# assert w_int has the correct size\n",
    "assert w_int.size() == torch.Size([3,1,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for wx in w_int:\n",
    "    plt.imshow(wx)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h_int = #TODO\n",
    "# assert h_int has the correct size\n",
    "assert h_int.size() == torch.Size([3,32,1])                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for hx in h_int:\n",
    "    plt.imshow(hx)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<details>\n",
    "\n",
    "<summary>Solution 1 avec <code>torch.logical_and</code></summary>    \n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# initialisation du tenseur w_int avec les valeurs [0,...,31]\n",
    "w_int = torch.arange(W).repeat(batch_size,1,1) # batch de vecteurs ligne \n",
    "# Returns the mask applying ((x1 ⩽ x) and (x ⩽ x2))\n",
    "w_int = torch.logical_and(w_int >= x1.view(-1,1,1), w_int <= x2.view(-1,1,1)) # vecteurs ligne\n",
    "\n",
    "# initialisation du tenseur h_int avec les valeurs [0,...,31]\n",
    "h_int = torch.arange(H).repeat(batch_size,1).unsqueeze(2) # batch de vecteurs colonne\n",
    "# Returns the mask applying ((y1 ⩽ y) and (y ⩽ y2))\n",
    "h_int = torch.logical_and(h_int >= y1.view(-1,1,1), h_int <= y2.view(-1,1,1)) # vecteurs colonne\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary>Solution 2 avec <code>torch.cumsum</code></summary>\n",
    "    \n",
    "<br>\n",
    "\n",
    "On initialise les éléments correspondant aux coordonnées `x1` et `y1` à `1`. <br>\n",
    "On initialise les éléments correspondant aux coordonnées `x2` et `y2` à `-1`. <br>\n",
    "Puis on utilise la fonction [torch.cumsum](https://pytorch.org/docs/stable/generated/torch.cumsum.html) pour remplir chaque intervalle `[x1,x2]` et `[y1,y2]` de `1`, le reste de `0`.\n",
    "    \n",
    "**Remarque :** il y a une petite erreur dans cette solution qui n'a pas d'impact majeur. +1 sur votre appréciation finale si vous la trouvez !!    \n",
    "    \n",
    "```python\n",
    "w_int = torch.zeros(batch_size,1,W) # vecteurs ligne \n",
    "w_int[range(batch_size),0,x1] = 1.\n",
    "w_int[range(batch_size),0,x2] = -1.\n",
    "w_int = torch.cumsum(w_int, dim=2).bool() # vecteurs ligne\n",
    "\n",
    "h_int = torch.zeros(batch_size,H,1) # vecteurs colonne\n",
    "h_int[range(batch_size),y1,0] = 1.\n",
    "h_int[range(batch_size),y2,0] = -1.\n",
    "h_int = torch.cumsum(h_int, dim=1).bool() # vecteurs colonne\n",
    "```\n",
    "<br> \n",
    "<details>\n",
    "    \n",
    "<summary>Solution +++</summary>\n",
    "\n",
    "<br>\n",
    "    \n",
    "Avec la solution précédente, les bornes `x2` et `y2` sont exclues de la fenêtre. Pour les inclure, il faudrait définir la valeur `-1` sur les `x2+1`ème et `y2+1`ème éléments :\n",
    "\n",
    "```python\n",
    "w_int[range(batch_size),0,x2+1] = -1.\n",
    "h_int[range(batch_size),y2+1,0] = -1.   \n",
    "```\n",
    "\n",
    "Cela entraîne des cas particuliers si `x2=31` ou `y2=31`. Pour gérer ces exceptions sans introduire de `if` :\n",
    "    \n",
    "```python\n",
    "# if x2==31, set w_int(.,0,31)=0, otherwize set w_int(.,0,x2+1)=-1\n",
    "w_int[.,0,torch.minimum(torch.tensor([31]).repeat(batch_size),x2+1)]=torch.maximum(torch.tensor([-1.]).repeat(batch_size),x2-31)\n",
    "# if y2==31, set h_int(.,31,0)=0, otherwize set h_int(.,y2+1,0)=-1\n",
    "h_int[.,torch.minimum(torch.tensor([31]).repeat(batch_size),y2+1,0)]=torch.maximum(torch.tensor([-1.]).repeat(batch_size),y2-31)\n",
    "```\n",
    "    \n",
    "</details>\n",
    "    \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Création des batches de masques intérieurs et extérieurs**\n",
    "\n",
    "* Multiplication des vecteurs h_int et w_int pour obtenir les masques intérieurs pour chaque image du batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiplication des vecteurs colonne \"hauteur\" h_int par les vecteurs ligne \"largeur\" w_int\n",
    "mask_int = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation des masques intérieurs pour chaque image du batch\n",
    "for m in mask_int:\n",
    "    plt.imshow(m)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "# multiplication des vecteurs colonne \"hauteur\" h_int par les vecteurs ligne \"largeur\" w_int\n",
    "mask_int = h_int*w_int\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Puis création des masques extérieurs à partir des masques intérieurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<details>\n",
    "\n",
    "<summary>Aide</summary>\n",
    "    \n",
    "Par exemple en utilisant la fonction [torch.logical_not](https://pytorch.org/docs/stable/generated/torch.logical_not.html).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les masques extérieurs sont les complémentaires des masques intérieurs\n",
    "mask_ext = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation des masques extérieurs\n",
    "for m in mask_ext:\n",
    "    plt.imshow(m)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<details>\n",
    "\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "# les masques extérieurs sont les complémentaires des masques intérieurs\n",
    "mask_ext = torch.logical_not(mask_int)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implémentation de la fonction de création d'un batch de masques**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, l'idée est d'implémenter ce qui a été fait dans les cellules précédentes dans une fontion générique, en ajoutant un choix sur le *device* d'exécution.\n",
    "\n",
    "**TODO** : implémenter la fonction de création des masques dans la cellule suivante. Les entrées de la fonction sont : \n",
    "* les coordonnées `x1`, `x2`, `y1`, `y2`, \n",
    "* le `batch_size`, \n",
    "* la largeur`W` de l'image, \n",
    "* la hauteur `H` de l'image, \n",
    "* le `device` de calcul.\n",
    "\n",
    "**Important** : Pour les images RGB (*channel* de 3), il faut rajouter une dimension en deuxième position dans les masques finaux ([doc .unsqueeze()](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html#torch-unsqueeze)) :\n",
    "```python\n",
    "    # rajouter une dimension en 2e position pour pouvoir traiter des images RGB\n",
    "    mask_int = mask_int.unsqueeze(1) \n",
    "    mask_ext = mask_ext.unsqueeze(1) \n",
    "```\n",
    "\n",
    "**Attention** : Ne pas oublier le paramètre `device=device` à chaque création d'un nouveau *Tensor*. Par exemple pour :\n",
    "```python\n",
    "    w_int = torch.zeros(batch_size,1,W,device=device)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_mask(x1, x2, y1, y2, batch_size, W, H, device=None):\n",
    "    \n",
    "    #TODO\n",
    "    \n",
    "    return mask_ext, mask_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de la fonction implémentée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,    \n",
    "                                           batch_size=16,\n",
    "                                           shuffle=True)\n",
    "batch = next(iter(train_loader))\n",
    "print('X train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[0].shape, batch[0].dtype, batch[0].element_size()*batch[0].nelement()))\n",
    "print('Y train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[1].shape, batch[1].dtype, batch[1].element_size()*batch[1].nelement()))\n",
    "\n",
    "imgs, targets = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "W = image_size\n",
    "H = image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = torch.rand(batch_size)\n",
    "s_index = torch.randperm(batch_size)      # Shuffle index\n",
    "rand_x = torch.randint(W, (batch_size,))\n",
    "rand_y = torch.randint(H, (batch_size,))\n",
    "cut_rat = torch.sqrt(1. - lam) ## cut ratio according to the random lambda\n",
    "\n",
    "x1 = torch.clip(rand_x - rand_x / 2, min=0).long()\n",
    "x2 = torch.clip(rand_x + rand_x / 2, max=W-1).long()\n",
    "y1 = torch.clip(rand_y - rand_y / 2, min=0).long()\n",
    "y2 = torch.clip(rand_y + rand_y / 2, max=H-1).long()\n",
    "\n",
    "mask_ext, mask_int = cut_mask(x1, x2, y1, y2, batch_size, W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérifier si le masque intérieur et l'image ont le même nombre de dimensions\n",
    "try:\n",
    "    assert imgs.dim() == mask_int.dim()\n",
    "    print('OK!')\n",
    "except:\n",
    "    print(f'Mismatch: \\n dim imgs = {imgs.dim()} \\n dim mask int = {mask_int.dim()} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérifier si le masque extérieur et l'image ont le même nombre de dimensions\n",
    "try:\n",
    "    assert imgs.dim() == mask_ext.dim()\n",
    "    print('OK!')\n",
    "except:\n",
    "    print(f'Mismatch: \\n dim imgs = {imgs.dim()} \\n dim mask ext = {mask_ext.dim()} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = mask_ext * imgs + mask_int * imgs[s_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    img = imgs[i].numpy().transpose((1,2,0))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis si le résultat est satisfaisant, intégrer la fonction dans le code [cutmix.py](cutmix.py).\n",
    "\n",
    "### Intégration de la nouvelle version dans cutmix.py\n",
    "\n",
    "**TODO :** dans le script [cutmix.py](cutmix.py), ajouter la fonction `cut_mask` définie dans la cellule plus haut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'dlojz_da_3.py -b {bs_optim} --image-size {image_size} --test'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'éviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['888412']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Garage](images/stop.png \"Arrêtez-vous ici! Une présentation vous attend avant le prochain TP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.3.0_py3.11.5",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-2.3.0_py3.11.5"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
