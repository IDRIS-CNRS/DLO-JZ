{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLO-JZ WebDataset, Data Augmentation - Jour 3 \n",
    "\n",
    "![car](./images/noun-car-repair-32305.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Objet du notebook\n",
    "\n",
    "Le but de ce *notebook* est d'optimiser la *DataLoader* afin de ne pas ralentir la boucle d'apprentissage. L'étude de la performance des solutions optimisées se fera en visualisant les traces du *profiler* :\n",
    "\n",
    "* **TP 1** : Optimisation du DataLoader au format Webdataset\n",
    "* **TP 2** : Data Augmentation\n",
    "\n",
    "Les cellules dans ce *notebook* ne sont pas prévues pour être modifiées, sauf rares exceptions indiquées dans les commentaires. Les TP se feront en modifiant le code `dlojz.py`.\n",
    "\n",
    "Les directives de modification seront marquées par l'étiquette **TODO :** dans le *notebook* suivant.\n",
    " \n",
    "Les solutions sont présentes dans le répertoire `solutions`.\n",
    "\n",
    "*Notebook rédigé par l'équipe assistance IA de l'IDRIS, juin 2023*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environnement de calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un module PyTorch doit avoir été chargé pour le bon fonctionnement de ce Notebook. **Nécessairement**, le module `pytorch-gpu/py3/1.11.0` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!module list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions *python* de gestion de queue SLURM dévelopées par l'IDRIS et les fonctions dédiées à la formation DLO-JZ sont à importer.\n",
    "\n",
    "Le module d'environnement pour les *jobs* et la taille des images sont fixés pour ce *notebook*.\n",
    "\n",
    "**TODO :** choisir un *pseudonyme* (maximum 5 caractères) pour vous différencier dans la queue SLURM et dans les outils collaboratifs pendant la formation et la compétition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idr_pytools import display_slurm_queue, gpu_jobs_submitter, search_log\n",
    "from dlojz_tools import controle_technique, compare, GPU_underthehood, plot_accuracy, lrfind_plot, imagenet_starter, turbo_profiler\n",
    "MODULE = 'pytorch-gpu/py3/1.11.0'\n",
    "account = 'for@v100'\n",
    "name = 'pseudo'   ## Pseudonyme à choisir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion de la queue SLURM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie permet d'afficher et de gérer la queue SLURM.\n",
    "\n",
    "Pour afficher toute la queue *utilisateur* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque**: Cette fonction utilisée plusieurs fois dans ce *notebook* permet d'afficher la queue de manière dynamique, rafraichie toutes les 5 secondes. Cependant elle ne s'arrête que lorsque la queue est vide. Si vous désirez reprendre la main sur le *notebook*, il vous suffira d'arrêter manuellement la cellule avec le bouton *stop*. Cela a bien sûr aucun impact sur le *scheduler* SLURM. Les *jobs* ne seront pas arrêtés.\n",
    "\n",
    "Si vous voulez annuler un *job* dans votre queue, décommenter la ligne suivante et remplacer le numéro du *job*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!scancel 2088207"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie *debug* permet d'afficher les fichiers de sortie et les fichiers d'erreur du *job*.\n",
    "\n",
    "Il est nécessaire dans la cellule suivante d'indiquer le *jobid* correspondant sous le format donné.\n",
    "\n",
    "***Remarque*** : dans ce notebook, lorsque vous soumettrez un *job*, vous recevrez en retour le numéro du job dans le format suivant : `jobid = ['123456']`. La cellule ci-dessous peut ainsi être facilement actualisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['2088207']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fichier de sortie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat {search_log(contains=jobid[0])[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fichier d'erreur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat {search_log(contains=jobid[0], with_err=True)['stderr'][0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "### Différence entre deux scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le *debug* ou pour comparer son code avec les solutions mises à disposition, la fonction suivante permet d'afficher une page html contenant un différentiel de fichiers texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"dlojz.py\"\n",
    "s2 = \"./solutions/dlojz3_1.py\"\n",
    "compare(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir le résultat du différentiel de fichiers sur la page suivante (attention au spoil !) :\n",
    "\n",
    "[compare.html](compare.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## Garage - Mise à niveau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fixe le *batch size* et la taille d'image pour ce TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_optim = 512\n",
    "image_size = 176"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO :** Comparer votre script `dlojz.py` avec ce qu'il devrait être actuellement. Si il y a des divergences, veuillez les corriger (par exemple en copiant-collant la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"dlojz.py\"\n",
    "s2 = \"./solutions/dlojz3_0.py\"\n",
    "compare(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir le résultat du différentiel de fichiers sur la page suivante :\n",
    "\n",
    "[compare.html](compare.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copier/coller la solution si nécessaire\n",
    "#!cp solutions/dlojz3_0.py dlojz.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3_1 : Optimisation du DataLoader - Format WebDataset\n",
    "\n",
    "Le but de ce TP est d'utiliser un *IterableDataset* sur des données d'entrée au format *WebDataset*  et de le comparer avec le *Dataset Map-style* de *torchvision* précédemment vu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation du format WebDataset\n",
    "**TODO** : dans le script `dlojz.py` :\n",
    "* Importer la librairie *webdataset*.\n",
    "```python\n",
    "import webdataset as wds\n",
    "```\n",
    "\n",
    "* Remplacer l'implémentation du `train_dataset`, du `train_loader` et du `train_sampler` par l'implémentation suivante.\n",
    "```python\n",
    "    train_dataset = (\n",
    "        wds.WebDataset(os.environ['ALL_CCFRSCRATCH']+'/imagenet/webdataset/imagenet_train-{000000..000127}.tar', shardshuffle=True, nodesplitter=wds.split_by_node)\n",
    "        .shuffle(1000)\n",
    "        .decode(\"torchrgb\")\n",
    "        .to_tuple('input.pyd', 'output.pyd')\n",
    "        .map_tuple(transform, lambda x: x)\n",
    "        .batched(mini_batch_size)\n",
    "        )\n",
    "    \n",
    "    dataset_size = 1281167\n",
    "    number_of_batches = dataset_size // global_batch_size\n",
    "    train_loader = wds.WebLoader(train_dataset,\n",
    "                                 batch_size=None,\n",
    "                                 num_workers=args.num_workers,\n",
    "                                 persistent_workers=args.persistent_workers,\n",
    "                                 pin_memory=args.pin_memory,\n",
    "                                 prefetch_factor=args.prefetch_factor,\n",
    "                                 drop_last=args.drop_last)\n",
    "    \n",
    "    train_loader = train_loader.slice(number_of_batches)\n",
    "    train_loader.length = number_of_batches\n",
    "```    \n",
    "\n",
    "* Puisqu'il n'y a plus de `train_sampler` (la distribution des *batches* sur les différents *workers* se fait avec le paramètre `nodesplitter=wds.split_by_node`), effacer ou commenter la ligne suivante :\n",
    "```python\n",
    "   #train_sampler.set_epoch(epoch)\n",
    "```\n",
    "\n",
    "* Un *dataset* de type *IterableDataset* ne connaissant pas sa longueur, la longueur du *loader* est définie par `train_loader.length = number_of_batches`. Modifier la déclaration de la variable `N_batch` en conséquence :\n",
    "```python\n",
    "    N_batch = train_loader.length\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Contrôle technique (version sous-optimisée)\n",
    "\n",
    "**TODO** : lancer l'exécution sur 50 itérations (`--test-nsteps 50`) sans profiling pour passer un contrôle technique qui servira de référence. **Cette exécution va prendre quelques minutes, vous pouvez passer à la suite du TP sans attendre la fin de l'exécution.**\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'dlojz.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 50'\n",
    "command += f' --num-workers 0 --no-persistent-workers --no-pin-memory --no-non-blocking --prefetch-factor 2'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00', constraint='v100-32g')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['1587014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des traces profiler Tensorboard (version sous-optimisée)\n",
    "**TODO** : étudier les traces du cas sous-optimisé \"`num_workers=0`\" afin de mesurer l'accélération brute de ce type de *Dataset*.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'dlojz.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 15 --prof'\n",
    "command += f' --num-workers 0 --no-persistent-workers --no-pin-memory --no-non-blocking --prefetch-factor 2'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00', constraint='v100-32g')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['1587676']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : vérifier qu'une trace a bien été générée dans le répertoire `profiler/<name>_<jobid>_bs512_is176/` sous la forme d'un fichier `.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls profiler/{name}_{jobid[0]}*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : visualiser cette trace grâce à l'application TensorBoard ([retrouver la procédure](#visu_tensorboard_gpu)) et comparer les traces obtenues avec le dataset *torchvision* et le dataset *webdataset*.\n",
    "\n",
    "**IMPORTANT** : une fois le TP terminé, penser à quitter l'instance JupyterHub pour **libérer le GPU** ( *> Hub Control Panel > Cancel* )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des paramètres d'optimisation du DataLoader\n",
    "Ensuite, l'objectif de ce TP  est de réduire le temps passé sur CPU par le DataLoader **WebDataset**.\n",
    "\n",
    "Les différentes optimisations proposées par le DataLoader sont accessibles dans le script `dlojz.py` via les arguments :\n",
    "* `--num-workers <num_workers>` (défaut à `10`)\n",
    "* `--persistent-workers` (défaut) ou `--no-persistent-workers`\n",
    "* `--pin-memory` (défaut) ou `--no-pin-memory`\n",
    "* `--non-blocking` (défaut) ou `--no-non-blocking`\n",
    "* `--prefetch-factor <prefetch_factor>` (défaut à `3`)\n",
    "* `--drop-last` ou `--no-drop-last` (défaut)\n",
    "\n",
    "**TODO** : faire varier ces différents paramètres et observer leurs effets grâce au profiler `turbo_profiler`\n",
    "\n",
    "Remarque : pour cette étude, on ne lance les exécutions que sur 15 itérations (--test-nsteps 15) pour avancer plus rapidement. \n",
    "\n",
    "Les différents essais seront stockés dans une *DataFrame* `dataloader_trials` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataloader_trials = pd.DataFrame({\"jobid\":pd.Series([],dtype=str),\n",
    "                                  \"num_workers\":pd.Series([],dtype=int),\n",
    "                                  \"persistent_workers\":pd.Series([],dtype=str),\n",
    "                                  \"pin_memory\":pd.Series([],dtype=str),\n",
    "                                  \"non_blocking\":pd.Series([],dtype=str),\n",
    "                                  \"prefetch_factor\":pd.Series([],dtype=int),\n",
    "                                  \"drop_last\":pd.Series([],dtype=str),\n",
    "                                  \"loading_time\":pd.Series([],dtype=float),\n",
    "                                  \"training_time\":pd.Series([],dtype=float)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'dlojz.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 15'\n",
    "\n",
    "# paramètres d'entrée correspondant aux optimisations du DataLoader\n",
    "command += ' --num-workers 0' \n",
    "command += ' --no-persistent-workers'\n",
    "command += ' --no-pin-memory'\n",
    "command += ' --no-non-blocking'\n",
    "command += ' --prefetch-factor 2'\n",
    "command += ' --no-drop-last'\n",
    "\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00', constraint='v100-32g')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['1587801']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call turbo_profiler\n",
    "dataloader_trial = turbo_profiler(jobid,dataloader_info=True)\n",
    "# store result in \"dataloader_trials\" DataFrame\n",
    "dataloader_trials = pd.concat([dataloader_trials,dataloader_trial], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afficher le tableau récapitulatif, trier par ordre croissant du LOADING_TIME\n",
    "dataloader_trials.sort_values(\"loading_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afficher le tableau récapitulatif, trier par ordre croissant du TRAINING_TIME\n",
    "dataloader_trials.sort_values(\"training_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des traces profiler avec TensorBoard (version optimisée)\n",
    "**TODO** : après avoir choisi un lot de paramètres optimal, relancer le job en réactivant le profiler PyTorch (argument d'entrée `--prof`) afin de visualiser les traces sous TensorBoard.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'dlojz.py -b {bs_optim} --image-size {image_size} --test --prof --test-nsteps 15'\n",
    "\n",
    "# définir ici les paramètres optimaux \n",
    "command += ' --num-workers 0' \n",
    "command += ' --no-persistent-workers'\n",
    "command += ' --no-pin-memory'\n",
    "command += ' --no-non-blocking'\n",
    "command += ' --prefetch-factor 2'\n",
    "command += ' --no-drop-last'\n",
    "\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00', constraint='v100-32g')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'éviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : vérifier qu'une trace a bien été générée dans le répertoire `profiler/<name>_<jobid>_bs512_is176/` sous la forme d'un fichier `.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls profiler/{name}_{jobid[0]}*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : visualiser cette trace grâce à l'application TensorBoard ([retrouver la procédure](#visu_tensorboard_gpu)). \n",
    "\n",
    "**IMPORTANT** : une fois le TP terminé, penser à quitter l'instance JupyterHub pour **libérer le GPU** ( *> Hub Control Panel > Cancel* )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Contrôle technique (version optimisée)\n",
    "\n",
    "**TODO** : lancer l'exécution sur 50 itérations (`--test-nsteps 50`) sans profiling pour passer un nouveau contrôle technique, à comparer avec celui de référence.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'dlojz.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 50'\n",
    "\n",
    "# définir ici les paramètres optimaux \n",
    "command += ' --num-workers 0' \n",
    "command += ' --no-persistent-workers'\n",
    "command += ' --no-pin-memory'\n",
    "command += ' --no-non-blocking'\n",
    "command += ' --prefetch-factor 2'\n",
    "command += ' --no-drop-last'\n",
    "\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00', constraint='v100-32g')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['1587014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Garage](images/stop.png \"Arrêtez-vous ici! Une présentation vous attend avant le prochain TP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3_2 : Data Augmentation\n",
    "## TP3_2_0 : RandAugment\n",
    "\n",
    "Le but de ce TP est d'ajouter la transformation `RandAugment` (disponible dans *torchvision*) dans la liste des transformations pour la *Data Augmentation* et de mesurer grâce au *profiler* ce que cela implique pour le *DataLoader*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut repartir d'un script`dlojz.py` propre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copier/coller la solution si nécessaire\n",
    "!cp solutions/dlojz3_0.py dlojz.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "        transforms.RandomResizedCrop(176),  # Random resize - Data Augmentation\n",
    "        transforms.RandomHorizontalFlip(),  # Horizontal Flip - Data Augmentation\n",
    "        transforms.RandAugment(5, 9),       # Random Augmentation 2: n operations, 9 : magnitude \n",
    "        transforms.ToTensor()               # convert the PIL Image to a tensor\n",
    "        ])\n",
    "    \n",
    "    \n",
    "train_dataset = torchvision.datasets.ImageNet(root=os.environ['ALL_CCFRSCRATCH']+'/imagenet',\n",
    "                                                  transform=transform)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,    \n",
    "                                           batch_size=4,\n",
    "                                           shuffle=True)\n",
    "batch = next(iter(train_loader))\n",
    "print('X train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[0].shape, batch[0].dtype, batch[0].element_size()*batch[0].nelement()))\n",
    "print('Y train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[1].shape, batch[1].dtype, batch[1].element_size()*batch[1].nelement()))\n",
    "\n",
    "for i in range(4):\n",
    "    img = batch[0][i].numpy().transpose((1,2,0))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO :** dans le script `dlojz.py` :\n",
    "* Rajouter la transformation `RandAugment`dans la liste des transformations pour la *Data Augmentation*\n",
    "```python\n",
    "transform = transforms.Compose([ \n",
    "        transforms.RandomResizedCrop(args.image_size),  # Random resize - Data Augmentation\n",
    "        transforms.RandomHorizontalFlip(),              # Horizontal Flip - Data Augmentation\n",
    "        transforms.RandAugment(2, 9),                   # Random Augmentation 2:n operations, 9:magnitude \n",
    "        transforms.ToTensor(),                          # convert the PIL Image to a tensor\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                             std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f'dlojz.py -b {bs_optim} --image-size {image_size} --test'\n",
    "command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'dlojz.py -b {bs_optim} --image-size {image_size} --test'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00', constraint='v100-32g')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'éviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['1588551']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Commentaires](images/cedez.png \"Assurez-vous que tout se passe bien avant de continuer!\")\n",
    "\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP3_2_1 : Mixup\n",
    "\n",
    "Le but de ce TP est d'ajouter la transformation `Mixup` dans la liste des transformations pour la *Data Augmentation* et de mesurer grâce au *profiler* ce que cela implique pour le *DataLoader*.\n",
    "\n",
    "La transformation `MixUp` n'est pas disponible dans *torchvision*, le script est disponible dans le répertoire `mixup/`. On notera que cette transformation impacte à la fois l'image et le *label*.\n",
    "\n",
    "On choisira, comme cela est fait habituellement, de *mixer* 2 images présentes dans le *batch* généré par le *DataLoader*. Donc cette transformation sera faite dans la boucle d'apprentissage après génération du *batch* et après toutes autres transformations liées à la *Data Augmentation*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "        transforms.RandomResizedCrop(176),  # Random resize - Data Augmentation\n",
    "        transforms.RandomHorizontalFlip(),  # Horizontal Flip - Data Augmentation\n",
    "        transforms.ToTensor()               # convert the PIL Image to a tensor\n",
    "        ])\n",
    "    \n",
    "    \n",
    "train_dataset = torchvision.datasets.ImageNet(root=os.environ['ALL_CCFRSCRATCH']+'/imagenet',\n",
    "                                                  transform=transform)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mixup.mixup import mixup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,    \n",
    "                                           batch_size=16,\n",
    "                                           shuffle=True)\n",
    "batch = next(iter(train_loader))\n",
    "print('X train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[0].shape, batch[0].dtype, batch[0].element_size()*batch[0].nelement()))\n",
    "print('Y train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[1].shape, batch[1].dtype, batch[1].element_size()*batch[1].nelement()))\n",
    "\n",
    "imgs, targets = batch\n",
    "imgs, targets = mixup_data(imgs, targets, num_classes=1000, alpha=2)        ## Transformation Mixup\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    img = imgs[i].numpy().transpose((1,2,0))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(f'target : {torch.max(targets, dim=1)[1][i]}, lambda : {torch.max(targets, dim=1)[0][i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paramètre alpha pour la beta distribution**\n",
    "\n",
    "Dans le script `mixup.py`, la variable `lambda` (`lam`) correspond à la proportion de la première image par rapport à la deuxième image. Elle est choisie aléatoirement suivant une **distribution bêta** définie sur [0, 1].\n",
    "\n",
    "Le paramètre `alpha` agit sur la forme de la distribution bêta. `alpha = 1` correspond à une distribution uniforme, `alpha < 1` favorise un tirage au sort de valeurs proches des bornes `0.` ou `1.`, et  `alpha > 1` favorise un tirage au sort de valeurs proches du centre `0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in [0.5, 1., 2.]:\n",
    "    plt.hist(np.random.beta(alpha, alpha, 1000000), bins=50, density=True, histtype='step')\n",
    "    plt.title(f'alpha={alpha}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Mixup sur CPU\n",
    "\n",
    "**TODO :** dans le script `dlojz.py` :\n",
    "* Importer la transformation `Mixup`\n",
    "```python\n",
    "from mixup.mixup import mixup_data\n",
    "```\n",
    "\n",
    "\n",
    "* Rajouter la transformation `MixUp` dans la boucle d'apprentissage **avant d'envoyer** le *batch* d'images et de *labels* **au GPU**.\n",
    "```python\n",
    "    # distribution of images and labels to all GPUs                                \n",
    "    images, labels = mixup_data(images, labels, num_classes=1000, alpha=2.)\n",
    "    images = images.to(gpu, non_blocking=True)\n",
    "    labels = labels.to(gpu, non_blocking=True)\n",
    "```\n",
    "\n",
    "* Dans le calcul des métriques à la fin de la boucle d'apprentissage, étant donné que les *labels* ne sont plus des *id* de classes mais des vecteurs de type *one hot encoded*, il faut ajouter la ligne suivante pour calculer les valeurs maximales des vecteurs :  \n",
    "```python\n",
    "    # Metric mesurement\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    labels = torch.argmax(labels, dim=1)     ### line to add for Mixup and Cutmix\n",
    "    accuracy = (predicted == labels).sum() / labels.size(0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f'dlojz.py -b {bs_optim} --image-size {image_size} --test'\n",
    "command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'dlojz.py -b {bs_optim} --image-size {image_size} --test'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00', constraint='v100-32g')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'éviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['1910208']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Mixup sur GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO :** dans le script `dlojz.py` :\n",
    "* Appliquer la transformation `MixUp` dans la boucle d'apprentissage **après avoir envoyé** le *batch* d'images et de *labels* **au GPU**.\n",
    "```python\n",
    "    # distribution of images and labels to all GPUs                                \n",
    "    #images, labels = mixup_data(images, labels, num_classes=1000, alpha=2.) ## ligne déplacée\n",
    "    images = images.to(gpu, non_blocking=args.non_blocking)\n",
    "    labels = labels.to(gpu, non_blocking=args.non_blocking)\n",
    "    images, labels = mixup_data(images, labels, num_classes=1000, alpha=2., device=gpu)\n",
    "```\n",
    "\n",
    "**TODO :** dans le script `mixup/mixup.py` :\n",
    "* Ajouter le paramètre `device=device` à chaque fois que l'on crée un nouveau *Tensor* pour qu'il soit stocké en mémoire au bon emplacement (CPU ou GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'dlojz.py -b {bs_optim} --image-size {image_size} --test'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00', constraint='v100-32g')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'éviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['1910460']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Commentaires](images/cedez.png \"Assurez-vous que tout se passe bien avant de continuer!\")\n",
    "\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP3_2_2 : Cutmix\n",
    "\n",
    "Le but de ce TP est d'ajouter la transformation `CutMix` dans la liste des transformations pour la *Data Augmentation* et de mesurer grâce au *profiler* ce que cela implique pour le *DataLoader*.\n",
    "\n",
    "La transformation `CutMix` n'est pas disponible dans *torchvision*, le script est disponible dans le répertoire `cutmix/`. On notera que cette transformation impacte à la fois l'image et le *label*.\n",
    "\n",
    "On choisira, comme cela est fait habituellement, de *mixer* 2 images présentes dans le *batch* généré par le dataloader. Donc cette transformation sera faite dans la boucle d'apprentissage après génération du *batch* et donc après toutes autres transformations liées à la *Data Augmentation*.\n",
    "\n",
    "Dans le script `cutmix.py`, la variable `lambda` (`lam`) correspond à la proportion de la première image par rapport à la deuxième image. Elle est choisie aléatoirement suivant une **distribution uniforme** définie sur [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "        transforms.RandomResizedCrop(176),  # Random resize - Data Augmentation\n",
    "        transforms.RandomHorizontalFlip(),  # Horizontal Flip - Data Augmentation\n",
    "        transforms.ToTensor()               # convert the PIL Image to a tensor\n",
    "        ])\n",
    "    \n",
    "    \n",
    "train_dataset = torchvision.datasets.ImageNet(root=os.environ['ALL_CCFRSCRATCH']+'/imagenet',\n",
    "                                                  transform=transform)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cutmix.cutmix import cutmix_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,    \n",
    "                                           batch_size=16,\n",
    "                                           shuffle=True)\n",
    "batch = next(iter(train_loader))\n",
    "print('X train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[0].shape, batch[0].dtype, batch[0].element_size()*batch[0].nelement()))\n",
    "print('Y train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[1].shape, batch[1].dtype, batch[1].element_size()*batch[1].nelement()))\n",
    "\n",
    "imgs, targets = batch\n",
    "imgs, targets = cutmix_data(imgs, targets, num_classes=1000)\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    img = imgs[i].numpy().transpose((1,2,0))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(f'target : {torch.max(targets, dim=1)[1][i]}, lambda : {torch.max(targets, dim=1)[0][i]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation CutMix sur GPU\n",
    "\n",
    "**TODO :** dans le script `dlojz.py` :\n",
    "* Importer la transformation `CutMix`\n",
    "```python\n",
    "from cutmix.cutmix import cutmix_data\n",
    "```\n",
    "\n",
    "* Rajouter la transformation `CutMix` dans la boucle d'apprentissage **après avoir envoyé** le *batch* d'images et de *labels* **au GPU**.\n",
    "```python\n",
    "    # distribution of images and labels to all GPUs\n",
    "    images = images.to(gpu, non_blocking=args.non_blocking)\n",
    "    labels = labels.to(gpu, non_blocking=args.non_blocking)\n",
    "    images, labels = cutmix_data(images, labels, num_classes=1000, device=gpu)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'dlojz.py -b {bs_optim} --image-size {image_size} --test'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00', constraint='v100-32g')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'éviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['226430']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation de la transformation CutMix\n",
    "Le code précédent utilise une boucle `for` qui empêche de distribuer la transformation sur les *cores* du GPU. Chaque image dans le *batch* est traitée de manière séquentielle.\n",
    "\n",
    "Le but de cette partie est d'optimiser le code de *CutMix* en générant du calcul matriciel adapté à une parallélisation sur GPU. Il s'agira de manipuler des tenseurs de tailles proportionnelles au *batch size* et d'utiliser des fonctions d'algèbre linéaire pour aboutir au même résultat numérique tout en accélérant le calcul.\n",
    "\n",
    "En d'autres termes, au lieu de constituer un masque par image, nous allons directement créer un *batch* de masques pour tout un *batch* d'images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Création d'un batch de masques**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, pour comprendre la procédure, nous travaillerons avec un *batch* de 3 images de taille `32x32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "batch_size = 3\n",
    "W = 32\n",
    "H = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En entrée, on connait les coordonnées des coins du cadre à découper pour chaque image du *batch* (voir illustration ci-dessous). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordonnee min dans la largeur pour chaque image du batch\n",
    "x1 = torch.Tensor([10, 5, 23]).long()\n",
    "# coordonne max dans la largeur pour chaque image du batch\n",
    "x2 =  torch.Tensor([20, 25, 31]).long()\n",
    "# coordonnee min dans la hauteur pour chaque image du batch\n",
    "y1 =  torch.Tensor([5, 10, 0]).long()\n",
    "# coordonne max dans la hauteur pour chaque image du batch\n",
    "y2 =  torch.Tensor([10, 22, 20]).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cutmix_opt](./images/cutmix_opt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Création des vecteurs ligne \"largeur\" w_int et des vecteurs colonne \"hauteur\" h_int pour tout le batch d'images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation à zéro\n",
    "w_int = torch.zeros(batch_size,1,W) # vecteurs ligne\n",
    "h_int = torch.zeros(batch_size,H,1) # vecteurs colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On initialise les éléments correspondant aux coordonnées minimales (`x1` et `y1`) à `1`. <br>\n",
    "On initialise les éléments correspondant aux coordonnées maximales (`x2` et `y2`) à `-1`. <br>\n",
    "Par la suite, les intervalles `[x1,x2]` et `[y1,y2]` seront remplis de `1` en demandant à remplir chaque vecteur avec la somme cumulée de ses éléments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = torch.arange(0,batch_size)\n",
    "# initialisation des indices correspondant aux coord min x1 et y1 à 1\n",
    "w_int[batch_idx,0,x1] = 1.\n",
    "h_int[batch_idx,y1,0] = 1.\n",
    "\n",
    "# initialisation des indices correspondant aux coord max x2 et y2 à -1\n",
    "w_int[batch_idx,0,x2] = -1.\n",
    "h_int[batch_idx,y2,0] = -1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation des vecteurs ligne \"largeur\" w_int\n",
    "for wx in w_int:\n",
    "    plt.imshow(wx)\n",
    "    plt.clim(-1,1)\n",
    "    plt.colorbar(ticks=np.arange(-1,2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation des vecteurs colonne \"hauteur\"\n",
    "for hx in h_int:\n",
    "    plt.imshow(hx)\n",
    "    plt.clim(-1,1)\n",
    "    plt.colorbar(ticks=np.arange(-1,2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour créer nos vecteurs w_int et h_int, on remplit chaque intervalle `[x1,x2]` et `[y1,y2]` de `1` en utilisant la fonction `torch.cumsum` pour cumuler les valeurs des éléments des vecteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cumsum(input, dim, *, dtype=None, out=None) → Tensor\n",
    "# Returns the cumulative sum of elements of input in the dimension dim.\n",
    "# Parameters\n",
    "#        input (Tensor) – the input tensor.\n",
    "#        dim (int) – the dimension to do the operation over\n",
    "\n",
    "w_int = torch.cumsum(w_int, dim=2) # vecteurs ligne\n",
    "h_int = torch.cumsum(h_int, dim=1) # vecteurs colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation des vecteurs masques \"largeur\"\n",
    "for wx in w_int:\n",
    "    plt.imshow(wx)\n",
    "    plt.clim(-1,1)\n",
    "    plt.colorbar(ticks=np.arange(-1,2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation des vecteurs masques \"hauteur\"\n",
    "for hx in h_int:\n",
    "    plt.imshow(hx)\n",
    "    plt.clim(-1,1)\n",
    "    plt.colorbar(ticks=np.arange(-1,2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Créations du batch de masques intérieurs et extérieurs**\n",
    "\n",
    "* Multiplication des vecteurs h_int et w_int pour obtenir les masques intérieurs pour chaque image du batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiplication des vecteurs colonne \"hauteur\" h_int par les vecteurs ligne \"largeur\" w_int\n",
    "mask_int = h_int*w_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation des masques intérieurs pour chaque image du batch\n",
    "for m in mask_int:\n",
    "    plt.imshow(m)\n",
    "    plt.clim(-1,1)\n",
    "    plt.colorbar(ticks=np.arange(-1,2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Puis, création des masques extérieurs à partir des masques intérieurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les masques extérieurs sont les complémentaires des masques intérieurs\n",
    "mask_ext = mask_int * (-1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation des masques extérieurs\n",
    "for m in mask_ext:\n",
    "    plt.imshow(m)\n",
    "    plt.clim(-1,1)\n",
    "    plt.colorbar(ticks=np.arange(-1,2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implémentation de la fonction de création d'un batch de masques**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, l'idée est d'implémenter ce qui a été fait dans les cellules précédentes dans une fontion générique, en ajoutant un choix sur le *device* d'exécution.\n",
    "\n",
    "**TODO** : implémenter la fonction de création des masques dans la cellule suivante. Les entrées de la fonction sont : \n",
    "* les coordonnées `x1`, `x2`, `y1`, `y2`, \n",
    "* le `batch_size`, \n",
    "* la largeur`W` de l'image, \n",
    "* la hauteur `H` de l'image, \n",
    "* le `device` de calcul.\n",
    "\n",
    "**Important** : Pour les images RGB (*channel* de 3), il faut rajouter une dimension en deuxième position dans les masques finaux :\n",
    "```python\n",
    "    # rajouter une dimension en 2e position pour pouvoir traiter des images RGB\n",
    "    mask_int = mask_int.unsqueeze(1) \n",
    "    mask_ext = mask_ext.unsqueeze(1) \n",
    "```\n",
    "\n",
    "**Attention** : Ne pas oublier le paramètre `device=device` à chaque création d'un nouveau *Tensor*. Par exemple pour :\n",
    "```python\n",
    "    w_int = torch.zeros(batch_size,1,W,device=device)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_mask(x1, x2, y1, y2, batch_size, W, H, device=None):\n",
    "    \n",
    "    mask_ext, mask_int = None, None\n",
    "    \n",
    "    ### TODO\n",
    "\n",
    "    return mask_ext, mask_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de la fonction implémentée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,    \n",
    "                                           batch_size=16,\n",
    "                                           shuffle=True)\n",
    "batch = next(iter(train_loader))\n",
    "print('X train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[0].shape, batch[0].dtype, batch[0].element_size()*batch[0].nelement()))\n",
    "print('Y train batch, shape: {}, data type: {}, Memory usage: {} bytes'\n",
    "      .format(batch[1].shape, batch[1].dtype, batch[1].element_size()*batch[1].nelement()))\n",
    "\n",
    "imgs, targets = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "W = 176\n",
    "H = 176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = torch.rand(batch_size)\n",
    "s_index = torch.randperm(batch_size)      # Shuffle index\n",
    "rand_x = torch.randint(W, (batch_size,))\n",
    "rand_y = torch.randint(H, (batch_size,))\n",
    "cut_rat = torch.sqrt(1. - lam) ## cut ratio according to the random lambda\n",
    "\n",
    "x1 = torch.clip(rand_x - rand_x / 2, min=0).long()\n",
    "x2 = torch.clip(rand_x + rand_x / 2, max=W-1).long()\n",
    "y1 = torch.clip(rand_y - rand_y / 2, min=0).long()\n",
    "y2 = torch.clip(rand_y + rand_y / 2, max=H-1).long()\n",
    "\n",
    "mask_ext, mask_int = cut_mask(x1, x2, y1, y2, batch_size, W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérifier si le masque et l'image ont le même nombre de dimensions\n",
    "try:\n",
    "    assert imgs.dim() == mask_int.dim()\n",
    "    print('OK!')\n",
    "except:\n",
    "    print(f'Mismatch: \\n dim imgs = {imgs.dim()} \\n dim mask = {mask_int.dim()} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = mask_ext * imgs + mask_int * imgs[s_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    img = imgs[i].numpy().transpose((1,2,0))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis si le résultat est satisfaisant, intégrer la fonction dans le code `cutmix/cutmix.py`.\n",
    "\n",
    "**TODO :** dans le script `cutmix/cutmix.py`, ajouter la fonction `cut_mask` définie dans la cellule plus haut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'dlojz.py -b {bs_optim} --image-size {image_size} --test'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00', constraint='v100-32g')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'éviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['256363']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-1.11.0_py3.9.12",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-1.11.0_py3.9.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
