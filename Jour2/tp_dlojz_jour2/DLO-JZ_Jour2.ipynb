{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLO-JZ Optimisation de l'apprentissage - Jour 2\n",
    "\n",
    "Optimisation système d'une boucle d'apprentissage *Resnet-50*.\n",
    "\n",
    "![car](./images/optimisation.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Objet du notebook\n",
    "\n",
    "Le but de ce *notebook* est d'optimiser un code d'apprentissage d'un modèle *Resnet-50* sur *Imagenet* pour Jean Zay en implémentant :\n",
    "* **TP 1** : la distribution (*Data Parallelism*)\n",
    "* **TP 2** : le *Profiler* PyTorch\n",
    "* **TP 3** : l'optimisation du *Dataloader*\n",
    "\n",
    "Les cellules dans ce *notebook* ne sont pas prévues pour être modifiées, sauf rares exceptions indiquées dans les commentaires. Les TP se feront en modifiant les codes `dlojz2_X.py`.\n",
    "\n",
    "Les directives de modification seront marquées par l'étiquette **TODO** dans le *notebook* suivant.\n",
    " \n",
    "Les solutions sont présentes dans le répertoire `solutions/`.\n",
    "\n",
    "*Notebook rédigé par l'équipe assistance IA de l'IDRIS, janvier 2024*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environnement de calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un module PyTorch doit avoir été chargé pour le bon fonctionnement de ce Notebook. **Nécessairement**, le module `pytorch-gpu/py3/2.1.1` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!module list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions *python* de gestion de queue SLURM développées par l'IDRIS et les fonctions dédiées à la formation DLO-JZ sont à importer.\n",
    "\n",
    "Le module d'environnement pour les *jobs* et la taille des images sont fixés pour ce *notebook*.\n",
    "\n",
    "**TODO :** choisir un pseudonyme (maximum 5 caractères) pour vous différencier dans la queue SLURM pendant la formation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from idr_pytools import display_slurm_queue, gpu_jobs_submitter, search_log\n",
    "from dlojz_tools import controle_technique, compare, GPU_underthehood, plot_accuracy, lrfind_plot, imagenet_starter, comm_profiler, turbo_profiler, BatchNorm_view\n",
    "MODULE = 'pytorch-gpu/py3/2.1.1'\n",
    "image_size = 224\n",
    "account = 'for@a100'\n",
    "name = 'pseudo'   ## Pseudonyme à choisir\n",
    "\n",
    "assert name != 'pseudo' and name != '', 'please choose a pseudo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un répertoire `checkpoints/` si cela n'a pas déjà été fait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion de la queue SLURM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour afficher vos jobs dans la queue SLURM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque**: cette fonction sera utilisée plusieurs fois dans ce *notebook*. Elle permet d'afficher la queue de manière dynamique, rafraichie toutes les 5 secondes. Elle ne s'arrête que lorsque la queue est vide. Si vous désirez reprendre la main sur le *notebook*, il vous suffira d'arrêter manuellement la cellule avec le bouton *stop*. Cela n'a bien sûr aucun impact sur les *jobs* soumis.\n",
    "\n",
    "Si vous voulez retirer TOUS vos *jobs* de la queue SLURM, décommenter et exécuter la cellule suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!scancel -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous voulez retirer UN de vos *jobs* de la queue SLURM, décommenter, compléter et exécuter la cellule suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!scancel <jobid>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie *debug* permet d'afficher les fichiers de sortie et les fichiers d'erreur du *job*.\n",
    "\n",
    "Il est nécessaire dans la cellule suivante (en décommentant) d'indiquer le *jobid* correspondant sous le format suivant.\n",
    "\n",
    "***Remarque*** : dans ce notebook, lorsque vous soumettrez un *job*, vous recevrez en retour le numéro du job dans le format suivant : `jobid = ['123456']`. La cellule ci-dessous peut ainsi être facilement actualisée.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobid = ['1493206']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fichier de sortie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cat {search_log(contains=jobid[0])[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fichier d'erreur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cat {search_log(contains=jobid[0], with_err=True)['stderr'][0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "### Différence entre deux scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour comparer son code avec les solutions mises à disposition, la fonction suivante permet d'afficher une page HTML contenant un différentiel de fichiers texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s1 = \"./dlojz2_1.py\"\n",
    "s2 = \"./solutions/dlojz2_1.py\"\n",
    "compare(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir le résultat du différentiel de fichiers sur la page suivante (attention au spoil !) :\n",
    "\n",
    "[compare.html](compare.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garage - Mise à niveau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fixe la taille d'image pour ce TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit le *batch size* optimal d'après les expériences du Jour 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Choisir un batch size optimal\n",
    "bs_optim = 512   ##TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------\n",
    "# TP2_1 : Distribution - Parallélisme de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir la [documentation de l'IDRIS](http://www.idris.fr/jean-zay/gpu/jean-zay-gpu-torch-multi.html).\n",
    "\n",
    "**TODO** : dans le script [dlojz2_1.py](./dlojz2_1.py) :\n",
    "* Importer les librairies liées à la distribution et au *Data Parallelism*.\n",
    "\n",
    "* Configurer et initialiser l'environnement parallèle.\n",
    "\n",
    "* Associer le bon GPU alloué au *process* actif.\n",
    "\n",
    "* Basculer le modèle en mode *DistributedDataParallelism* pour qu'il soit dupliqué sur les différents GPU.\n",
    "\n",
    "* Définir les *samplers* distribués `train_sampler` et `val_sampler` et les utiliser dans `train_loader` et `val_loader` respectivement. ***Attention***, le *shuffling* devra être délégué aux samplers.\n",
    "    \n",
    "* Au tout début de la boucle d'apprentissage, indiquer au *sampler* l'*epoch* en cours afin d'obtenir un *shuffling* différent à chaque *epoch*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz2_1.py -b {bs_optim} --image-size {image_size} --test --chkpt' \n",
    "n_gpu = 4\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['832153']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communications\n",
    "#### Découverte de comm_profiler\n",
    "Pour ce TP, nous avons implémenté un profiler maison léger `comm_profiler` basé sur les traces de DEBUG de NCCL pour visualiser la quantité et le type de communications collectives échangées pendant une boucle d'apprentissage distribuée sur plusieurs GPU.\n",
    "\n",
    "**À noter :** dans le script python [dlojz2_1.py](./dlojz2_1.py) les variables de trace de *DEBUG* *NCCL* sont configurées comme suit :\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "    os.environ[\"NCCL_DEBUG_SUBSYS\"] = \"INIT,COLL\"\n",
    "    # display info\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comm_profiler(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Commentaires](images/cedez.png \"Assurez-vous que tout se passe bien avant de continuer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNorm Layer & SyncBatchNorm Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rappel** :\n",
    "\n",
    "Pendant l'apprentissage, la couche normalise ses sorties en utilisant la moyenne et l'écart type du batch d'entrée.\n",
    "Plus exactement, la couche retourne `(batch - mean(batch)) / (var(batch) + epsilon) * weight + bias` , avec :\n",
    "\n",
    "* `epsilon`, une petite constante pour éviter la division par 0,\n",
    "* `weight`, un facteur appris (entraîné) avec un calcul de gradient lors de la backpropagation et qui est initialisé à 1,\n",
    "* `bias`, un facteur appris (entraîné) avec un calcul de gradient lors de la backpropagation et qui est initialisé à 0.\n",
    "\n",
    "Pendant l'inférence ou la validation, la couche normalise ses sorties en utilisant en plus des `weight` et `bias` entraînés, les facteurs `running_mean` et `running_var` : `(batch - running_mean) / (running_var + epsilon) * weight + bias`.\n",
    "\n",
    "`running_mean` et `running_var` sont des facteurs non entraînés, mais qui sont mis à jour à chaque itération de batch lors de l'apprentissage, selon la méthode suivante :\n",
    "\n",
    "* `running_mean = running_mean * momentum + mean(batch) * (1 - momentum)`\n",
    "* `running_var = running_var * momentum + var(batch) * (1 - momentum)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BatchNorm_view(jobid, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionnel : SyncBatchNorm layer\n",
    "Voir la [documentation PyTorch](http://www.idris.fr/ia/syncbn.html#syncbn_en_pytorch).\n",
    "\n",
    "**TODO** : dans le script [dlojz2_1.py](./dlojz2_1.py) :\n",
    "* Juste avant la bascule du modèle en mode *DistributedDataParallelism*, transformer les couches *BatchNorm* du modèle en couches *SyncBatchNorm*.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz2_1.py -b {bs_optim} --image-size {image_size} --test --chkpt'\n",
    "n_gpu = 4\n",
    "jobid_sync = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid_sync = {jobid_sync}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### jobid_sync = ['832493']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BatchNorm_view(jobid + jobid_sync, model, labels=['BN Layer', 'SyncBN Layers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Communications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comm_profiler(jobid_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Garage](images/stop.png \"Arrêtez-vous ici! Une présentation vous attend avant le prochain TP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## Garage - Mise à niveau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "On fixe le *batch size* et la taille d'image pour ce TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_optim = 512\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2_2 : Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation du profiler PyTorch\n",
    "\n",
    "Voir la [documentation de l'IDRIS](http://www.idris.fr/jean-zay/pre-post/profiler_pt.html).\n",
    "\n",
    "**TODO** : dans le script [dlojz2_2.py](./dlojz2_2.py) :\n",
    "\n",
    "* Importer les librairies liées au *profiler* PyTorch.\n",
    "\n",
    "* Configurer le *profiler* et ses paramètres.\n",
    "\n",
    "```python\n",
    "    # pytorch profiler setup\n",
    "\tprof =  profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                    schedule=schedule(wait=1, warmup=1, active=5, repeat=1),\n",
    "                    on_trace_ready=tensorboard_trace_handler('./profiler/' + os.environ['SLURM_JOB_NAME'] \n",
    "                                               + '_' + os.environ['SLURM_JOBID'] + '_bs' +\n",
    "                                               str(mini_batch_size)  + '_is' + str(args.image_size)),\n",
    "                    profile_memory=True,\n",
    "                    record_shapes=False, \n",
    "                    with_stack=False,\n",
    "                    with_flops=False\n",
    "                    )\n",
    "```\n",
    "\n",
    "* Englober toute la boucle d'apprentissage (validation comprise) dans le *context* `prof`.\n",
    "\n",
    "\n",
    "* Indiquer au *profiler* la fin de chaque itération d'apprentissage (avant la validation).\n",
    "\n",
    "\n",
    "### Génération d'une trace profiler\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "__Remarques__ : \n",
    "* le profilage sera actif sur 5 *steps* donc nous n'exécutons l'entraînement que sur 7 steps grâce à l'argument `--test-nsteps=7`.\n",
    "* les arguments `--num-workers 0 --no-persistent-workers --no-pin-memory --no-non-blocking --prefetch-factor 2` utilisés dans la commande ci-dessous servent à supprimer certaines optimisations déjà présentes dans le script `dlojz.py`. Ces optimisations seront détaillées dans le prochain chapitre du cours.\n",
    "\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz2_2.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 7'\n",
    "command += f' --num-workers 0 --no-persistent-workers --no-pin-memory --no-non-blocking --prefetch-factor 2'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['810461']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : vérifier qu'une trace a bien été générée dans le répertoire `profiler/<name>_<jobid>_bs512_is224/` sous la forme d'un fichier `.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tree profiler/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des traces profiler avec TensorBoard <a id=\"visu_tensorboard_gpu\"></a>\n",
    "\n",
    "**TODO** : visualiser cette trace grâce à l'application TensorBoard en suivant les étapes suivantes :\n",
    "* ouvrir [jupyterhub.idris.fr](https://jupyterhub.idris.fr) dans un nouvel onglet du navigateur\n",
    "* ouvrir une nouvelle instance JupyterHub en cliquant sur **Add New JupyterLab Instance**\n",
    "* sélectionner **Spawn server on SLURM node** (on va réserver un GPU)\n",
    "* sélectionner **Tensorboard** dans le menu **Frontend**\n",
    "* définir le chemin des logs **$WORK/DLO-JZ/Jour2/tp_dlojz_jour2/profiler** dans **TensorBoard logs directory**\n",
    "\n",
    "<div><img src=\"images/slurm_spawner_a100_tensorboard.png\" width=\"550\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sélectionner l'option avancée `--partition=Octo-GPU A100 SXM4 with 80 GB GPU mem`\n",
    "\n",
    "<div><img src=\"images/slurm_spawner_a100_tensorboard_advanced.png\" width=\"550\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* lancer l'instance TensorBoard\n",
    "<div><img src=\"images/slurm_spawner_a100_tensorboard_start.png\" width=\"550\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remarque__ : le premier démarrage de TensorBoard peut prendre un peu de temps. Il faut parfois faire preuve d'un peu de patience lorsqu'on utilise cet outil mais ça en vaut la peine :)\n",
    "\n",
    "**TODO** : en naviguant dans les différents onglets du TensorBoard, chercher à répondre aux questions suivantes :\n",
    "* le GPU est-il bien utilisé ? (mémoire max utilisée, *occupancy*, *efficiency*)\n",
    "* la mémoire CPU est-elle saturée ?\n",
    "* les *TensorCores* sont-ils bien sollicités grâce à l'implémentation de la *mixed precision* ?\n",
    "* quelle partie de l'entraînement est la plus gourmande en temps ? se déroule-t-elle sur le CPU ou le GPU ?\n",
    "* essayer de repérer les grandes étapes de calcul sur la *timeline* de l'exécution (onglet *Trace*)\n",
    "\n",
    "**IMPORTANT** : une fois le TP terminé, penser à quitter l'instance JupyterHub pour **libérer le GPU** ( *> Hub Control Panel > Cancel* )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Garage](images/stop.png \"Arrêtez-vous ici! Une présentation vous attend avant le prochain TP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2_3 : Optimisation du DataLoader\n",
    "\n",
    "Dans ce TP, on utilisera alternativement les scripts [dlojz2_3.py](./dlojz2_3.py) (identique à la solution du TP2_1, version **sans profiler PyTorch**) et [dlojz2_2.py](./dlojz2_2.py) (version **avec profiler PyTorch**) qui ne seront pas modifiés.\n",
    "\n",
    "### Contrôle technique (version sous-optimisée)\n",
    "\n",
    "**TODO** : lancer l'exécution sur 50 itérations (`--test-nsteps 50`) sans profiling pour passer un contrôle technique qui servira de référence. **Cette exécution va prendre quelques minutes (~5min)**.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz2_3.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 50'\n",
    "command += f' --num-workers 0 --no-persistent-workers --no-pin-memory --no-non-blocking --prefetch-factor 2'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['810363']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Découverte de turbo_profiler\n",
    "Pour ce TP, nous avons implémenté un profiler maison léger `turbo_profiler` basé sur l'outil `Chronometer` pour visualiser le temps passé sur CPU (DataLoader) et sur GPU (le reste de l'itération). Ce profiler est moins précis mais cela nous permettra de désactiver le profiler PyTorch pour ne pas dégrader les performances et éviter de devoir ouvrir l'outil graphique TensorBoard à chaque fois pour visualiser les informations qui nous intéressent.\n",
    "\n",
    "**TODO** :  relancer l'exécution précédente sur 16 steps et découvrir le profiler `turbo_profiler`.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz2_3.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 16'\n",
    "command += f' --num-workers 0 --no-persistent-workers --no-pin-memory --no-non-blocking --prefetch-factor 2'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['811893']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : visualiser la sortie de `turbo_profiler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# call turbo_profiler\n",
    "dataloader_trial = turbo_profiler(jobid,dataloader_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via le turbo profiler, on va également récupérer et stocker les performances obtenues dans une DataFrame `dataloader_trials` :\n",
    "* initialisation de la DataFrame :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataloader_trials = pd.DataFrame({\"jobid\":pd.Series([],dtype=str),\n",
    "                                  \"num_workers\":pd.Series([],dtype=int),\n",
    "                                  \"persistent_workers\":pd.Series([],dtype=str),\n",
    "                                  \"pin_memory\":pd.Series([],dtype=str),\n",
    "                                  \"non_blocking\":pd.Series([],dtype=str),\n",
    "                                  \"prefetch_factor\":pd.Series([],dtype=int),\n",
    "                                  \"drop_last\":pd.Series([],dtype=str),\n",
    "                                  \"loading_time\":pd.Series([],dtype=float)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* stockage du résultat précédent dans la *DataFrame* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store result in \"dataloader_trials\" DataFrame\n",
    "dataloader_trials = pd.concat([dataloader_trials,dataloader_trial], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* visualisation du contenu de la *DataFrame* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# afficher le tableau récapitulatif, trier par ordre croissant du LOADING_TIME\n",
    "dataloader_trials.sort_values(\"loading_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des paramètres d'optimisation du DataLoader\n",
    "L'objectif de ce TP est de réduire le temps passé sur CPU par le DataLoader.\n",
    "\n",
    "Pour cette étude, on continue à lancer les exécutions sur 16 itérations seulement (`--test-nsteps 16`) pour avancer plus rapidement. \n",
    "\n",
    "Les différentes optimisations proposées par le DataLoader de PyTorch sont accessibles dans le script `dlojz.py` via les arguments :\n",
    "* `--num-workers <num_workers>` (défaut à `10`)\n",
    "* `--persistent-workers` (défaut) ou `--no-persistent-workers`\n",
    "* `--pin-memory` (défaut) ou `--no-pin-memory`\n",
    "* `--non-blocking` (défaut) ou `--no-non-blocking`\n",
    "* `--prefetch-factor <prefetch_factor>` (défaut à `3`)\n",
    "* `--drop-last` ou `--no-drop-last` (défaut)\n",
    "\n",
    "**TODO** : faire varier ces différents paramètres et observer leurs effets grâce au profiler `turbo_profiler`. Pour comparer les différents essais, ceux-ci seront stockés dans la *DataFrame* `dataloader_trials` initialisée plus tôt.\n",
    "\n",
    "1. Modifier un ou plusieurs paramètres du DataLoader et lancer l'exécution :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz2_3.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 16'\n",
    "\n",
    "# paramètres d'entrée correspondant aux optimisations du DataLoader\n",
    "command += ' --num-workers 0' \n",
    "command += ' --no-persistent-workers'\n",
    "command += ' --no-pin-memory'\n",
    "command += ' --no-non-blocking'\n",
    "command += ' --prefetch-factor 2'\n",
    "command += ' --no-drop-last'\n",
    "\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['811915']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Visualiser le retour du turbo profiler :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# call turbo_profiler\n",
    "dataloader_trial = turbo_profiler(jobid,dataloader_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "3. Stocker le nouveau résultat dans la DataFrame `dataloader_trials` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store result in \"dataloader_trials\" DataFrame\n",
    "dataloader_trials = pd.concat([dataloader_trials,dataloader_trial], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Visualiser et comparer l'ensemble des résultats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# afficher le tableau récapitulatif, trier par ordre croissant du LOADING_TIME\n",
    "dataloader_trials.sort_values(\"loading_time\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Répéter les étapes 1. à 4. jusqu'à avoir trouvé des paramètres d'optimisation satisaisants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des traces profiler avec TensorBoard (version optimisée)\n",
    "**TODO** : après avoir choisi un lot de paramètres optimal, relancer le job en **réactivant le profiler PyTorch** (i.e. en utilisant le script [dlojz2_2.py](./dlojz2_2.py)) afin de visualiser les traces sous TensorBoard, et les comparer avec la version sous-optimisée étudiée dans le TP2_2.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'./dlojz2_2.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 7'\n",
    "\n",
    "# définir ici les paramètres optimaux \n",
    "command += ' --num-workers 0' \n",
    "command += ' --no-persistent-workers'\n",
    "command += ' --no-pin-memory'\n",
    "command += ' --no-non-blocking'\n",
    "command += ' --prefetch-factor 2'\n",
    "command += ' --no-drop-last'\n",
    "\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'éviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['1732254']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : vérifier qu'une trace a bien été générée dans le répertoire `profiler/<name>_<jobid>_bs512_is224/` sous la forme d'un fichier `.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree profiler/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : visualiser cette trace grâce à l'application TensorBoard ([retrouver la procédure](#visu_tensorboard_gpu)). \n",
    "\n",
    "**IMPORTANT** : une fois le TP terminé, penser à quitter l'instance JupyterHub pour **libérer le GPU** ( *> Hub Control Panel > Cancel* )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrôle technique (version optimisée)\n",
    "\n",
    "**TODO** : lancer l'exécution sur 50 itérations (`--test-nsteps 50`) sans profiling pour passer un nouveau contrôle technique, à comparer avec celui de référence.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz2_3.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 50'\n",
    "\n",
    "# définir ici les paramètres optimaux \n",
    "command += ' --num-workers 16' \n",
    "command += ' --persistent-workers'\n",
    "command += ' --pin-memory'\n",
    "command += ' --non-blocking'\n",
    "command += ' --prefetch-factor 2'\n",
    "command += ' --drop-last'\n",
    "\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['812032']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Garage](images/stop.png \"Arrêtez-vous ici! Une présentation vous attend avant le prochain TP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.1.1_py3.11.5",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-2.1.1_py3.11.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
