{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLO-JZ Optimisation de l'apprentissage - Jour 2\n",
    "\n",
    "Optimisation système d'une boucle d'apprentissage *Resnet-152*.\n",
    "\n",
    "![car](./images/optimisation.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Objet du notebook\n",
    "\n",
    "Le but de ce *notebook* est d'optimiser un code d'apprentissage d'un modèle *Resnet-50* sur *Imagenet* pour Jean Zay en implémentant :\n",
    "* **TP 1** : l'optimisation du *Dataloader*\n",
    "* **TP 2** : la distribution (*Data Parallelism*)\n",
    "* **TP 3** : le DDP et le problème des paramètres non utilisés\n",
    "\n",
    "\n",
    "Les cellules dans ce *notebook* ne sont pas prévues pour être modifiées, sauf rares exceptions indiquées dans les commentaires. Les TP se feront en modifiant les codes `dlojz2_X.py`.\n",
    "\n",
    "Les directives de modification seront marquées par l'étiquette **TODO** dans le *notebook* suivant.\n",
    " \n",
    "Les solutions sont présentes dans le répertoire `solutions/`.\n",
    "\n",
    "*Notebook rédigé par l'équipe assistance IA de l'IDRIS, octobre 2025*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environnement de calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions *python* de gestion de queue SLURM développées par l'IDRIS et les fonctions dédiées à la formation DLO-JZ sont à importer.\n",
    "\n",
    "Le module d'environnement pour les *jobs* et la taille des images sont fixés pour ce *notebook*.\n",
    "\n",
    "**TODO :** choisir un pseudonyme (maximum 5 caractères) pour vous différencier dans la queue SLURM pendant la formation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from idr_pytools import display_slurm_queue, gpu_jobs_submitter, search_log\n",
    "from dlojz_tools import controle_technique, compare, comm_profiler, turbo_profiler, BatchNorm_view, metric_compute_log\n",
    "MODULE = 'pytorch-gpu/py3/2.4.0'\n",
    "image_size = 224\n",
    "account = 'for@a100'\n",
    "name = 'pseudo'   ## Pseudonyme à choisir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un répertoire `checkpoints/` si cela n'a pas déjà été fait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion de la queue SLURM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour afficher vos jobs dans la queue SLURM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque**: cette fonction sera utilisée plusieurs fois dans ce *notebook*. Elle permet d'afficher la queue de manière dynamique, rafraichie toutes les 5 secondes. Elle ne s'arrête que lorsque la queue est vide. Si vous désirez reprendre la main sur le *notebook*, il vous suffira d'arrêter manuellement la cellule avec le bouton *stop*. Cela n'a bien sûr aucun impact sur les *jobs* soumis.\n",
    "\n",
    "Si vous voulez retirer TOUS vos *jobs* de la queue SLURM, décommenter et exécuter la cellule suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!scancel -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous voulez retirer UN de vos *jobs* de la queue SLURM, décommenter, compléter et exécuter la cellule suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!scancel <jobid>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "### Différence entre deux scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour comparer son code avec les solutions mises à disposition, la fonction suivante permet d'afficher une page HTML contenant un différentiel de fichiers texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s1 = \"./dlojz2_2.py\"\n",
    "s2 = \"./solutions/dlojz2_2.py\"\n",
    "compare(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir le résultat du différentiel de fichiers sur la page suivante (attention au spoil !) :\n",
    "\n",
    "[compare.html](compare.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garage - Mise à niveau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fixe la taille d'image pour ce TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fixe le *batch size* optimal d'après les expériences du Jour 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs_optim = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2_1: Optimisation du DataLoader\n",
    "\n",
    "Dans ce TP, on utilisera le script [dlojz2_1.py](./dlojz2_1.py) dans lequel le profiler PyTorch n'est pas implémenté. Ce script est identique à la solution du TP2_1.\n",
    "\n",
    "Dans un premier temps, on va désactiver toutes les optimisations du DataLoader (**version sous-optimisée**). Ensuite,  nous pourrons observer l'impact de chacune des optimisations possibles en les réintégrant une par une."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Découverte de turbo_profiler\n",
    "Pour ce TP, nous avons implémenté un profiler maison léger `turbo_profiler` basé sur l'outil `Chronometer` pour visualiser le temps passé sur CPU (DataLoader) et sur GPU (le reste de l'itération). Ce profiler est moins précis mais cela nous permettra de désactiver le profiler PyTorch pour ne pas dégrader les performances et éviter de devoir ouvrir l'outil graphique TensorBoard à chaque fois pour visualiser les informations qui nous intéressent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version sous-optimisée\n",
    "\n",
    "**TODO** : lancer l'exécution sur 1 GPU et 50 itérations (`--test-nsteps 50`) sans profiling pour passer un contrôle technique qui servira de référence. Cela va prendre quelques minutes (~5min), **vous pouvez passer à la suite sans attendre la fin de l'exécution**.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz2_1.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 16'\n",
    "command += f' --num-workers 0 --no-persistent-workers --no-pin-memory --no-non-blocking'\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['90764']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizz\n",
    "\n",
    "L'éxécution étant assez longue, un quizz vous attend : [Quizz TP2_1](https://www.deepmama.com/quizz/dlojz_quizz4.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : visualiser la sortie de `turbo_profiler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# call turbo_profiler\n",
    "dataloader_trial = turbo_profiler(jobid,dataloader_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via le turbo profiler, on va également récupérer et stocker les performances obtenues dans une DataFrame `dataloader_trials` :\n",
    "* initialisation de la DataFrame :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataloader_trials = pd.DataFrame({\"jobid\":pd.Series([],dtype=str),\n",
    "                                  \"num_workers\":pd.Series([],dtype=int),\n",
    "                                  \"pin_memory\":pd.Series([],dtype=str),\n",
    "                                  \"non_blocking\":pd.Series([],dtype=str),\n",
    "                                  \"prefetch_factor\":pd.Series([],dtype=int),\n",
    "                                  \"persistent_workers\":pd.Series([],dtype=str),\n",
    "                                  \"drop_last\":pd.Series([],dtype=str),\n",
    "                                  \"loading_time\":pd.Series([],dtype=float),\n",
    "                                  \"1st_step_loading_time\":pd.Series([],dtype=float),\n",
    "                                  \"CPU_memory_usage(GB)\":pd.Series([],dtype=float)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* stockage du résultat précédent dans la *DataFrame* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store result in \"dataloader_trials\" DataFrame\n",
    "dataloader_trials = pd.concat([dataloader_trials,dataloader_trial], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* visualisation du contenu de la *DataFrame* :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# afficher le tableau récapitulatif, trier par ordre croissant du LOADING_TIME\n",
    "dataloader_trials.sort_values(\"loading_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des paramètres d'optimisation du DataLoader\n",
    "L'objectif de ce TP est de réduire le temps passé sur CPU par le DataLoader.\n",
    "\n",
    "Pour cette étude, on continue à lancer les exécutions sur 1 GPU et 50 itérations seulement (`--test-nsteps 50`) pour avancer plus rapidement. \n",
    "\n",
    "Les différentes optimisations proposées par le DataLoader de PyTorch sont accessibles dans le script `dlojz.py` via les arguments :\n",
    "* `--num-workers <num_workers>` (défaut à `8`)\n",
    "* `--persistent-workers` (défaut) ou `--no-persistent-workers`\n",
    "* `--pin-memory` (défaut) ou `--no-pin-memory`\n",
    "* `--non-blocking` (défaut) ou `--no-non-blocking`\n",
    "* `--prefetch-factor <prefetch_factor>` (défaut à `2`)\n",
    "* `--drop-last` ou `--no-drop-last` (défaut)\n",
    "\n",
    "**TODO** : faire varier ces différents paramètres et observer leurs effets grâce au profiler `turbo_profiler`. Pour comparer les différents essais, ceux-ci seront stockés dans la *DataFrame* `dataloader_trials` initialisée plus tôt.\n",
    "\n",
    "1. Modifier un ou plusieurs paramètres du DataLoader et lancer l'exécution :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "command = f'./dlojz2_1.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 50'\n",
    "\n",
    "# paramètres d'entrée correspondant aux optimisations du DataLoader\n",
    "command += ' --num-workers 2' \n",
    "command += ' --no-pin-memory'\n",
    "command += ' --no-non-blocking'\n",
    "command += ' --prefetch-factor 2'\n",
    "command += ' --no-persistent-workers'\n",
    "command += ' --no-drop-last'\n",
    "\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['2189183']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Visualiser le retour du turbo profiler :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# call turbo_profiler\n",
    "dataloader_trial = turbo_profiler(jobid,dataloader_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "3. Stocker le nouveau résultat dans la DataFrame `dataloader_trials` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store result in \"dataloader_trials\" DataFrame\n",
    "dataloader_trials = pd.concat([dataloader_trials,dataloader_trial], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Visualiser et comparer l'ensemble des résultats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# afficher le tableau récapitulatif, trier par ordre croissant du LOADING_TIME\n",
    "dataloader_trials.sort_values(\"loading_time\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Répéter les étapes 1. à 4. jusqu'à avoir trouvé des paramètres d'optimisation satisfaisants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrôle technique (version optimisée)\n",
    "\n",
    "**TODO** : relancer l'exécution sur 1 GPU et 100 itérations (`--test-nsteps 100`) sans profiling pour passer un nouveau contrôle technique, à comparer avec celui de référence.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz2_1.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 100'\n",
    "\n",
    "# définir ici les paramètres optimaux\n",
    "command += ' --num-workers 0' \n",
    "command += ' --no-pin-memory'\n",
    "command += ' --no-non-blocking'\n",
    "command += ' --prefetch-factor 2'\n",
    "command += ' --no-persistent-workers'\n",
    "command += ' --no-drop-last'\n",
    "\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['2189222']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_profiler(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONNEL : Visualisation des traces profiler avec TensorBoard (version sous optimisée)\n",
    "**TODO** : relancer le job en **réactivant le profiler PyTorch** dans le script [dlojz2_1.py](./dlojz2_1.py) (revoir le TP1_4) afin de visualiser les traces sous TensorBoard, et les comparer avec la version optimisée étudiée dans le TP1_4.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'./dlojz2_1.py -b {bs_optim} --image-size {image_size} --test --test-nsteps 8'\n",
    "command += f' --num-workers 0 --no-persistent-workers --no-pin-memory --no-non-blocking'\n",
    "\n",
    "n_gpu = 1\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'éviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['1732254']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : vérifier qu'une trace a bien été générée dans le répertoire `profiler/<name>_<jobid>_bs512_is224/` sous la forme d'un fichier `.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree profiler/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : visualiser cette trace grâce à l'application TensorBoard. \n",
    "\n",
    "**IMPORTANT** : une fois le TP terminé, penser à quitter l'instance JupyterHub pour **libérer le GPU** ( *> Hub Control Panel > Cancel* )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Garage](images/stop.png \"Arrêtez-vous ici! Une présentation vous attend avant le prochain TP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------\n",
    "## Garage - Mise à niveau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "bs_optim = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2_2 : Distribution - Parallélisme de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir la [documentation de l'IDRIS](http://www.idris.fr/jean-zay/gpu/jean-zay-gpu-torch-multi.html).\n",
    "\n",
    "**TODO** : dans le script [dlojz2_2.py](./dlojz2_2.py) :\n",
    "* Importer les librairies liées à la distribution et au *Data Parallelism*.\n",
    "\n",
    "* Configurer et initialiser l'environnement parallèle.\n",
    "\n",
    "* Associer le bon GPU alloué au *process* actif.\n",
    "\n",
    "* Basculer le modèle en mode *DistributedDataParallelism* pour qu'il soit dupliqué sur les différents GPU.\n",
    "\n",
    "* Définir les *samplers* distribués `train_sampler` et `val_sampler` et les utiliser dans `train_loader` et `val_loader` respectivement. ***Attention***, le *shuffling* devra être délégué aux samplers.\n",
    "    \n",
    "* Au tout début de la boucle d'apprentissage, indiquer au *sampler* l'*epoch* en cours afin d'obtenir un *shuffling* différent à chaque *epoch*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'./dlojz2_2.py -b {bs_optim} --image-size {image_size} --test --chkpt' \n",
    "n_gpu = 4\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid = ['712592']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizz\n",
    "\n",
    "L'éxécution étant assez longue, un quizz vous attend : [Quizz TP2_2](https://www.deepmama.com/quizz/dlojz_quizz5.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communications\n",
    "#### Découverte de comm_profiler\n",
    "Pour ce TP, nous avons implémenté un profiler maison léger `comm_profiler` basé sur les traces de DEBUG de NCCL pour visualiser la quantité et le type de communications collectives échangées pendant une boucle d'apprentissage distribuée sur plusieurs GPU.\n",
    "\n",
    "**À noter :** dans le script python [dlojz2_2.py](./dlojz2_2.py) les variables de trace de *DEBUG* *NCCL* sont configurées comme suit :\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "    os.environ[\"NCCL_DEBUG_SUBSYS\"] = \"INIT,COLL\"\n",
    "    # display info\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comm_profiler(jobid, n_display=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[from pytorch documentation : ](https://pytorch.org/docs/stable/notes/ddp.html#internal-design)\n",
    "\n",
    "> Each DDP process creates a local `Reducer`, which will take care of the gradients synchronization during the backward pass. To improve communication efficiency, the `Reducer` organizes parameter gradients into **buckets**, and reduces one bucket at a time. **Bucket size** can be configured by setting the bucket_cap_mb argument in DDP constructor. The mapping from parameter gradients to buckets is determined at the construction time, based on the bucket size limit and parameter sizes. \n",
    "\n",
    "\n",
    "![buckets](./images/buckets1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDP inter-noeud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons utilisé précédemment **4 GPU** sur le même nœud de calcul. Les bus de communication **intra-nœud** *NVLink* sont très rapide. **Le *scaling* est quasi parfait**.\n",
    "\n",
    "Si nous utilisons **32 GPU** en *DDP* avec 4 nœuds de calcul et donc des communications sur le réseau d'**interconnexion des nœuds** nous obtenons le résultat suivant.\n",
    "\n",
    "![DDP 32 GPU](./images/ddp32GPU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ce test n'est pas faisable pendant le TP par chacun d'entre vous, pour des raisons évidentes d'accès aux ressources. Veuillez vous reporter au résultat fourni ici.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronized Metrics Communications "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après la [documentation de TorchMetrics](https://lightning.ai/docs/torchmetrics/stable/pages/overview.html):\n",
    "\n",
    "> TorchMetrics is a Metrics API created for easy metric development and usage in PyTorch and PyTorch Lightning. It is rigorously tested for all edge cases and includes a growing list of common metric implementations.\n",
    ">\n",
    "> The metrics API provides `update()`, `compute()`, `reset()` functions to the user. The metric base class inherits `torch.nn.Module` which allows us to call `metric(...)` directly. The `forward()` method of the base Metric class serves the dual purpose of calling `update()` on its input and simultaneously returning the value of the metric over the provided input.\n",
    ">\n",
    "> These metrics work with **DDP** in PyTorch and PyTorch Lightning by default. When `.compute()` is called in distributed mode, the internal state of each metric is synced and reduced across each process, so that the logic present in `.compute()` is applied to state information from all processes.\n",
    "\n",
    "Dans le test précedent, nous appliquions un `compute()` des *metrics* toutes les **100 itérations** pendant l'apprentissage et à la fin de chaque validation. Nous ne pouvions donc voir les communications de synchronisation des *metrics* qu'à la fin de la validation.\n",
    "\n",
    "**Dans le test suivant,** nous appliquerons un `compute()` des *metrics* toutes les **8 itérations** d'apprentissage afin d'observer les communications des *metrics* pendant l'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'./dlojz2_2.py -b {bs_optim} --image-size {image_size} --test --metric-step 8' \n",
    "n_gpu = 4\n",
    "jobid_metric = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:04:00')\n",
    "print(f'jobid_metric  = {jobid_metric }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid_metric  = ['822402']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_profiler(jobid_metric, n_display=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoom sur les communications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_profiler(jobid_metric, zoom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valeurs des métriques avant et après les synchronisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_compute_log(jobid_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Commentaires](images/cedez.png \"Assurez-vous que tout se passe bien avant de continuer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNorm Layer & SyncBatchNorm Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rappel** :\n",
    "\n",
    "Pendant l'apprentissage, la couche normalise ses sorties en utilisant la moyenne et l'écart type du batch d'entrée.\n",
    "Plus exactement, la couche retourne `(batch - mean(batch)) / (var(batch) + epsilon) * weight + bias` , avec :\n",
    "\n",
    "* `epsilon`, une petite constante pour éviter la division par 0,\n",
    "* `weight`, un facteur appris (entraîné) avec un calcul de gradient lors de la backpropagation et qui est initialisé à 1,\n",
    "* `bias`, un facteur appris (entraîné) avec un calcul de gradient lors de la backpropagation et qui est initialisé à 0.\n",
    "\n",
    "Pendant l'inférence ou la validation, la couche normalise ses sorties en utilisant en plus des `weight` et `bias` entraînés, les facteurs `running_mean` et `running_var` : `(batch - running_mean) / (running_var + epsilon) * weight + bias`.\n",
    "\n",
    "`running_mean` et `running_var` sont des facteurs non entraînés, mais qui sont mis à jour à chaque itération de batch lors de l'apprentissage, selon la méthode suivante :\n",
    "\n",
    "* `running_mean = running_mean * momentum + mean(batch) * (1 - momentum)`\n",
    "* `running_var = running_var * momentum + var(batch) * (1 - momentum)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet152()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BatchNorm_view(jobid, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SyncBatchNorm layer\n",
    "Voir la [documentation PyTorch](http://www.idris.fr/ia/syncbn.html#syncbn_en_pytorch).\n",
    "\n",
    "**TODO** : dans le script [dlojz2_2.py](./dlojz2_2.py) :\n",
    "* Juste avant la bascule du modèle en mode *DistributedDataParallelism*, transformer les couches *BatchNorm* du modèle en couches *SyncBatchNorm*.\n",
    "\n",
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "command = f'./dlojz2_2.py -b {bs_optim} --image-size {image_size} --test --chkpt'\n",
    "n_gpu = 4\n",
    "jobid_sync = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid_sync = {jobid_sync}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#jobid_sync = ['2189317']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controle_technique(jobid_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BatchNorm_view(jobid + jobid_sync, model, labels=['BN Layer', 'SyncBN Layers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Communications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comm_profiler(jobid_sync, n_display=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Commentaires](images/cedez.png \"Assurez-vous que tout se passe bien avant de continuer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2_3 : DDP Advanced Parameters\n",
    "\n",
    "**TODO**: Voir la [documentaion Pytorch](https://docs.pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel) sur les paramètres de la *class* `torch.nn.parallel.DistributedDataParallel`.\n",
    "\n",
    "Les paramètres qui ne sont pas abordés dans la [documentation de l'IDRIS](http://www.idris.fr/jean-zay/gpu/jean-zay-gpu-torch-multi.html), ont peu d'intérêts, pour les petits modèles de la taille d'un Resnet-152.\n",
    "\n",
    "Cependant dans certains cas particuliers, le paramètre `find_unused_parameters` devient nécessaire. Nous allons donc étudier ce paramètre dans ce TP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find unused Parameters\n",
    "\n",
    "> **find_unused_parameters (bool)** – Traverse the autograd graph from all tensors contained in the return value of the wrapped module’s forward function. Parameters that don’t receive gradients as part of this graph are preemptively marked as being ready to be reduced. In addition, parameters that may have been used in the wrapped module’s forward function but were not part of loss computation and thus would also not receive gradients are preemptively marked as ready to be reduced. (default: False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Multi-head Classifier\n",
    "\n",
    "![Multi-head](./images/hydra.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous prenons ici, un modèle fantaisiste pour illustrer facilement un cas particulier de *unused parameters*.\n",
    "\n",
    "A la fin d'un *Resnet-152* nous ajoutons plusieurs têtes de classifications. Lors de chaque *forward*, une seule tête sera choisi aléatoirement.\n",
    "\n",
    "Nous sommes donc dans un cas où aléatoirement certaines couches, et donc certains **paramètres ne sont pas utilisés**. Observons ce qu'il se passe !\n",
    "\n",
    "Dans le fichier [dlojz2_3_1.py](./dlojz2_3_1.py), on initialise le modèle de la manière suivante, en utilisant le fichier [custom_models.py](./custom_models.py):\n",
    "\n",
    "```python\n",
    "import torchvision.models as models \n",
    "from custom_models import add_conditional_heads\n",
    "\n",
    "model = models.resnet152()\n",
    "model = add_conditional_heads(model, n_heads=3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du script avec `find_unused_parameters=False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'./dlojz2_3_1.py -b {bs_optim} --image-size {image_size} --test'\n",
    "n_gpu = 4\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['826927']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** : Aller lire le *error log* pour interpréter l'erreur remontée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du script avec `find_unused_parameters=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'./dlojz2_3_1.py -b {bs_optim} --image-size {image_size} --test --find-unused-parameters'\n",
    "n_gpu = 4\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['826960']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Depth\n",
    "\n",
    "![Stochastic Depth](./images/Stochastic-Depth.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le *Stochastic Depth* est une technique de *regularization* lors de l'apprentissage qui *drop* aléatoirement des *layers* entiers avec une probabilité de plus en plus forte selon la profondeur de la couche.\n",
    "\n",
    "Nous sommes donc dans un nouveau cas de **paramètres non utilisés** aléatoirement, que nous allons testé de la même manière que précedemment.\n",
    "\n",
    "Dans le fichier [dlojz2_3_2.py](./dlojz2_3_2.py), on initialise le modèle de la manière suivante, en utilisant le fichier [custom_models.py](./custom_models.py):\n",
    "\n",
    "```python\n",
    "from custom_models import resnet152_with_stochastic_depth\n",
    "\n",
    "model = resnet152_with_stochastic_depth()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du script avec `find_unused_parameters=False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soumission du *job*. **Attention vous sollicitez les noeuds de calcul à ce moment-là**.\n",
    "\n",
    "Pour soumettre le job, veuillez basculer la cellule suivante du mode `Raw NBConvert` au mode `Code`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "command = f'./dlojz2_3_2.py -b {bs_optim} --image-size {image_size} --test'\n",
    "n_gpu = 4\n",
    "jobid = gpu_jobs_submitter(command, n_gpu, MODULE, name=name,\n",
    "                    account=account, time_max='00:10:00')\n",
    "print(f'jobid = {jobid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier-coller la sortie `jobid = ['xxxxx']` dans la cellule suivante.\n",
    "\n",
    "Puis, rebasculer la cellule précédente en mode `Raw NBConvert`, afin d'eviter de relancer un job par erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobid = ['827157']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_slurm_queue(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_technique(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque**: Ici, on utilise des *masks* pour *drop* certaines *layers*. Tous les gradients — ainsi que les activations — sont donc bien calculés, puis remis à zéro lorsqu’ils sont masqués. Le graphe de calcul reste complet et identique pour chaque passage, ce qui évite tout problème de synchronisation des gradients entre processus.\n",
    "Dans ce contexte, le paramètre `find_unused_parameters` de **DDP** n’est pas nécessaire.\n",
    "\n",
    "En revanche, pour des architectures réellement dynamiques, comme les modèles à **routage conditionnel** (Mixture-of-Experts, Switch Transformers) ou les **classifieurs multi-head** activant des branches différentes selon l’entrée, l’approche par masquage devient coûteuse et peu réaliste.\n",
    "Dans ces cas, il est préférable d’activer `find_unused_parameters=True`, afin de permettre à DDP de gérer automatiquement les paramètres non utilisés lors du passage avant-arrière. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Garage](images/stop.png \"Arrêtez-vous ici! Une présentation vous attend avant le prochain TP.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.8.0_py3.12.11",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-2.8.0_py3.12.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
